{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "90676bf6",
      "metadata": {},
      "source": [
        "# For Colab T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "kAPGez1MZX5I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAPGez1MZX5I",
        "outputId": "a600bb03-fca9-4742-afb9-36065f0bf2d6"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "55489e6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55489e6d",
        "outputId": "cbacfd21-4c8d-4023-d95e-8443ad883fb8"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "raw_dataset = load_dataset(\"nlpai-lab/kullm-v2\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "14f65368",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14f65368",
        "outputId": "ee1a6154-533b-4507-dd71-96196eed196b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'instruction', 'input', 'output'],\n",
              "    num_rows: 152630\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "97594d0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97594d0d",
        "outputId": "4cf59298-a028-4906-b277-ff0e9bab4f20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['세 가지 기본 색은 빨강, 파랑, 노랑입니다. 이 색은 다른 색을 혼합하여 만들 수 없고 다른 모든 색은 다양한 비율로 조합하여 만들 수 있기 때문에 원색이라고 부릅니다. 빛에 사용되는 첨가제 색상 시스템에서 원색은 빨강, 녹색, 파랑(RGB)입니다.',\n",
              " 'AI 어시스턴트인 저는 저만의 개인적인 경험이나 물리적 존재를 가지고 있지 않습니다. 하지만 알고리즘, 논리, 데이터를 기반으로 의사 결정을 내리도록 프로그래밍되어 있습니다. 상충되는 정보나 여러 가지 가능한 결과가 있을 수 있기 때문에 의사결정이 어려운 상황에 직면할 때가 있습니다. 그런 경우 저는 각 옵션의 위험과 이점을 분석하고 비교하여 원하는 결과를 얻을 가능성이 가장 높은 결론에 도달할 수 있는 능력을 활용합니다.',\n",
              " '원자는 모든 물질의 기본 구성 요소이며 양성자, 중성자, 전자의 세 가지 유형의 입자로 이루어져 있습니다. 원자의 구조는 전자 구름으로 둘러싸인 중앙에 핵이 있는 것으로 설명할 수 있습니다.\\n\\n원자의 핵은 양성자와 중성자로 구성됩니다. 양성자는 양전하를 띠는 입자이고 중성자는 전하를 띠지 않는 중성 입자입니다. 이 두 입자는 원자의 중심에 있으며 원자 질량의 대부분을 차지하는 원자핵에 위치합니다.\\n\\n원자핵을 둘러싸고 있는 것은 전자 구름입니다. 전자는 음전하를 띠는 입자로, 원자핵 주변에서 끊임없이 움직입니다. 전자 구름은 껍질 또는 궤도로 나뉘며, 각 껍질은 특정 수의 전자를 보유할 수 있습니다. 원자가 껍질이라고 하는 가장 바깥쪽 껍질에 있는 전자의 수에 따라 원자의 화학적 특성이 결정됩니다.\\n\\n중성 원자에서 핵의 양성자 수는 전자 구름의 전자 수와 같으므로 양전하와 음전하가 균형을 이루며 원자는 전체 전하를 갖지 않습니다. 원자 번호라고도 하는 양성자의 수는 원자가 어떤 원소인지 결정합니다.',\n",
              " '대기 오염을 줄이는 방법에는 다음과 같은 여러 가지가 있습니다:\\n\\n1. 에너지 소비를 줄입니다: 에너지를 절약하면 발전소에서 배출되는 오염 물질의 양을 줄일 수 있습니다. 에너지 효율이 높은 가전제품과 조명을 사용하고, 집을 단열하며, 사용하지 않을 때는 조명과 전자기기를 끄는 등의 방법이 있습니다.\\n\\n2. 대중교통 또는 카풀 이용하기: 자동차와 트럭은 주요 오염원입니다. 대중교통, 카풀 또는 자전거를 이용하면 도로에 운행되는 자동차 수를 줄여 배기가스 배출량을 줄일 수 있습니다.\\n\\n3. 폐기물을 책임감 있게 처리하세요: 폐기물이 태워지거나 분해되면 유해 가스가 대기 중으로 방출될 수 있습니다. 유해 폐기물을 올바르게 처리하고 플라스틱, 종이, 유리와 같은 재료는 가능하면 재활용하세요.\\n\\n4. 청정 에너지원을 지원하세요: 태양열 및 풍력과 같은 재생 에너지원은 오염을 거의 또는 전혀 일으키지 않습니다. 청정 에너지 회사 및 프로젝트를 지원하고 집에 재생 에너지 시스템을 설치하는 것을 고려하세요.\\n\\n5. 효율적으로 운전하기: 운전을 해야 하는 경우, 차량을 잘 관리하고 급가속과 급제동을 피하고 공회전을 줄이는 등 효율적으로 운전하세요.\\n\\n6. 제품 선택에 유의하세요: 일부 제품과 관행은 다른 제품보다 오염 물질을 더 많이 배출합니다. 친환경 포장재를 사용한 제품을 선택하고 유해 화학 물질을 대기 중으로 방출할 수 있는 에어로졸 스프레이 사용을 최소화하세요.',\n",
              " '1. 균형 잡힌 영양가 있는 식단을 섭취합니다: 식단에 다양한 과일과 채소, 저지방 단백질, 통곡물, 건강한 지방이 포함되어 있는지 확인하세요. 이렇게 하면 신체가 최상의 기능을 발휘하는 데 필요한 필수 영양소를 공급하고 만성 질환을 예방하는 데 도움이 됩니다.\\n\\n2. 규칙적인 신체 활동을 합니다: 운동은 뼈, 근육, 심혈관 건강을 튼튼하게 유지하는 데 매우 중요합니다. 매주 150분 이상의 중간 강도의 유산소 운동 또는 75분 이상의 격렬한 운동을 목표로 하세요.\\n\\n3. 충분한 수면을 취합니다: 양질의 수면을 충분히 취하는 것은 신체적, 정신적 건강에 매우 중요합니다. 수면은 기분을 조절하고 인지 기능을 개선하며 건강한 성장과 면역 기능을 지원하는 데 도움이 됩니다. 매일 밤 7~9시간 수면을 목표로 하세요.',\n",
              " '물의 끓는점은 표준 대기압에서 섭씨 100도 또는 화씨 212도입니다.',\n",
              " '0, 2, 3, 4, 8.',\n",
              " '세계에서 가장 유명한 화가의 칭호는 주관적이며 개인의 의견에 따라 달라질 수 있습니다. 하지만 많은 사람들이 이탈리아 르네상스 시대의 유명한 예술가인 레오나르도 다빈치를 세계에서 가장 유명한 화가 중 한 명으로 꼽습니다. 그는 \"모나리자\"와 \"최후의 만찬\"을 비롯한 그의 상징적인 작품으로 유명합니다. 그 외에도 빈센트 반 고흐, 파블로 피카소, 미켈란젤로 등 세계에서 가장 유명한 화가 중 한 명으로 꼽히는 유명 화가들이 있습니다.',\n",
              " '메인보드 또는 시스템 보드라고도 하는 마더보드는 컴퓨터의 중앙 인쇄 회로 기판입니다. 마더보드는 컴퓨터의 백본 또는 기초 역할을 하며 CPU, RAM, 스토리지 드라이브, 확장 카드 및 주변 장치와 같은 다양한 구성 요소를 모두 연결합니다. 마더보드는 이러한 구성 요소 간의 통신 및 데이터 전송을 관리하여 함께 작동하고 지정된 작업을 수행할 수 있도록 합니다.\\n\\n또한 마더보드에는 여러 구성 요소에 전원을 공급하는 전원 조절 회로와 이러한 구성 요소의 작동을 동기화하는 클럭 생성기와 같은 중요한 회로가 포함되어 있습니다. 또한 부팅 프로세스를 제어하고 컴퓨터 하드웨어를 구성하고 관리하기 위한 인터페이스를 제공하는 펌웨어인 BIOS(기본 입력/출력 시스템)도 포함되어 있습니다. 마더보드의 다른 기능에는 내장 네트워킹, 오디오 및 비디오 기능이 포함될 수 있습니다.\\n\\n전반적으로 컴퓨터 마더보드의 기능은 컴퓨터를 구성하는 모든 다양한 구성 요소의 통합 및 작동을 위한 플랫폼을 제공하는 것으로, 모든 컴퓨팅 시스템의 필수적인 부분입니다.',\n",
              " '그는 5분 후에 도착하는 버스를 타기 위해 버스 정류장으로 달려갔습니다.',\n",
              " '프랑스의 수도는 파리입니다.',\n",
              " '동물: 코끼리\\n식물 참나무\\n광물 광물: 구리 광석',\n",
              " '화려하고 밝은 꽃으로 가득한 초원,\\n따스한 햇살에 끝없이 펼쳐진 푸른 하늘,\\n순수하고 진실한 멜로디를 노래하는 새들,\\n자연의 아름다움은 모든 색조로 가득합니다.\\n\\n부드러운 바람에 나뭇잎이 바스락거리는 소리,\\n벌들의 윙윙거리는 소리,\\n우아하고 유유히 흐르는 강물,\\n이 모든 것이 완벽한 조화를 이루죠.\\n\\n광대하고 웅장한 창조의 경이로움,\\n자연의 시가 내 손바닥에 펼쳐지네.',\n",
              " '1. 유감 표명하기\\n2. 속죄하다\\n3. 보상하기 위해',\n",
              " '정육면체의 표면적은 정육면체 중 하나의 면적을 계산한 다음 6을 곱하면 구할 수 있습니다(정육면체는 6개의 면을 가지고 있으므로). 정육면체의 면적은 단순히 한 변의 길이를 제곱한 값입니다.\\n\\n따라서 이 특정 큐브의 경우\\n\\n표면적 = 6 × (변 길이)²\\n             = 6 × (5cm)²\\n             = 6 × 25 cm²\\n             = 150 cm²\\n\\n이 정육면체의 총 표면적은 150제곱센티미터입니다.',\n",
              " '선장은 뉴스 보도를 읽었습니다.',\n",
              " '갈색 여우가 재빨리 뛰어올랐어요.',\n",
              " '다음은 재귀를 사용하여 숫자의 계승을 계산하는 새 버전의 코드입니다:\\n\\ndef factorial(num):\\n    if num == 0:\\n        return 1\\n    else:\\n        반환 num * 팩토리얼(num-1)',\n",
              " '데이터 집합의 중앙값을 찾으려면 데이터를 오름차순으로 정렬한 다음 중간 값을 찾아야 합니다. 이 경우 주어진 데이터는 이미 오름차순으로 정렬되어 있습니다. 데이터 집합에 5개의 값이 있으므로 중앙값은 세 번째 값인 중간 값이 됩니다. 따라서 주어진 데이터 집합의 중앙값은 7입니다.',\n",
              " '3D 모델을 만들고 싶어요! 하지만 저는 AI 언어 모델이라 시각적 모델을 만드는 데 필요한 도구가 없습니다. 블렌더, 스케치업 또는 오토캐드와 같은 모델링 소프트웨어를 사용하여 3D 모델을 만들어 보세요. 시작하는 방법을 모르는 경우 프로세스를 안내하는 수많은 온라인 튜토리얼을 찾을 수 있습니다.',\n",
              " '인터넷이 우리를 전 세계적으로 연결해주는 능력에도 불구하고 인터넷의 기본 기능, 일반적인 사용 및 잠재력을 이해하지 못하는 사람들이 있습니다.',\n",
              " '북미와 남미를 나누는 경도는 파나마-콜롬비아 국경이라고도 하는 77° 00\\' 0\" 또는 77°W입니다.',\n",
              " '재생 에너지 사용의 중요성은 아무리 강조해도 지나치지 않습니다. 태양열, 풍력, 수력 등의 재생 에너지원은 유한한 화석 연료와 달리 단기간에 자연적으로 보충할 수 있습니다. 재생 에너지를 활용하면 온실가스 배출량이 줄어들어 기후 변화의 영향을 완화하는 데 도움이 됩니다. 또한 비재생 에너지원에 대한 의존도를 줄여 에너지 자립과 안보를 증진할 수 있습니다. 또한 재생 에너지원은 장기적으로 더 저렴한 경우가 많으며 친환경 에너지 부문에서 일자리를 창출할 수 있습니다. 따라서 재생 에너지로의 전환은 지구의 건강과 미래의 지속 가능성을 위해 매우 중요합니다.',\n",
              " '캠핑 여행에 필요한 10가지 품목을 소개합니다:\\n\\n1. 텐트 - 쉼터와 비바람으로부터 보호하는 용도로 사용\\n2. 침낭 - 따뜻하고 편안한 잠자리를 위한 필수품\\n3. 휴대용 스토브 또는 캠프파이어 그릴 - 식사 요리용\\n4. 얼음 또는 아이스팩이 있는 쿨러 - 상하기 쉬운 음식과 음료를 차갑게 유지합니다.\\n5. 랜턴 또는 손전등 - 야간 조명 제공용\\n6. 구급상자 - 경미한 부상이나 질병에 대비합니다.\\n7. 지도와 나침반 또는 GPS - 하이킹 또는 지역 탐험 시 네비게이션용\\n8. 캠프 의자 또는 접이식 의자 - 캠프장 주변에서 편안하게 앉을 수 있는 의자\\n9. 방충제 - 벌레 물림을 방지합니다.\\n10. 자외선 차단제 - 햇볕으로부터 피부를 보호합니다.',\n",
              " '4x + 2y = 10이라는 방정식이 주어졌을 때, y의 값에 따라 x의 값에 대한 해는 무한히 많습니다. 다시 말해, x의 값은 y의 값에 따라 달라집니다.\\n\\n그러나 x를 y로 표현하는 것은 여전히 가능합니다. 이를 위해 방정식을 재정렬하여 x를 풀 수 있습니다:\\n\\n4x + 2y = 10\\n4x = 10 - 2y\\nx = (10 - 2y)/4\\n\\n따라서 방정식에 따르면 x의 값은 (10 - 2y)/4입니다. y의 특정 값을 알지 못하면 x의 정확한 값을 결정할 수 없습니다.',\n",
              " 'DNA는 디옥시리보핵산의 약자입니다. 모든 생명체의 성장, 발달, 기능 및 번식에 사용되는 유전적 지침을 전달하는 분자입니다.',\n",
              " '로마의 장군이자 정치가였던 율리우스 카이사르는 기원전 44년 3월 15일에 암살당했습니다. 폼페이 극장에서 열린 원로원 회의에서 스스로를 리베라토레스라고 칭하는 원로원 의원들이 칼에 찔려 죽었습니다. 가이우스 카시우스 롱기누스와 마르쿠스 주니우스 브루투스가 이끄는 이들은 카이사르의 독재가 로마 공화정을 전복시키고 있다고 믿고 전통적인 공화정을 회복하고자 했습니다. 정확한 암살자 수는 알려지지 않았지만 60여 명의 공모자가 암살에 참여했으며, 각자가 돌아가면서 카이사르를 찔렀다고 합니다. 그가 죽은 날은 여전히 3월의 이데스로 알려져 있습니다.',\n",
              " '분수 4/16은 두 분수가 같은 값을 나타내기 때문에 1/4과 같습니다. 분수와 분모를 모두 공통분수로 나누면 분수를 단순화할 수 있습니다. 이 경우 4는 4/16의 분자와 분모 모두의 공통 상수입니다. 둘을 4로 나누면 4/4 = 1과 16/4 = 4가 되므로 단순화된 분수는 1/4이 됩니다. 또는 곱셈의 관점에서 생각해 볼 수도 있습니다. 예를 들어 분수 1/4의 분자와 분모에 4를 곱하면 (1x4)/(4x4), 즉 4/16이 됩니다. 두 분수는 곱셈이나 나눗셈을 통해 다른 분수에서 같은 수로 도출할 수 있으므로 동일한 값을 나타내며 동등합니다.',\n",
              " '재활용에 관한 웹사이트의 로고를 디자인하려면 먼저 전통적인 재활용 화살표 심볼, 나뭇잎이나 나무, 흙빛 색상 등 재활용의 개념을 나타내는 콘셉트를 브레인스토밍하는 것부터 시작해야 합니다.\\n\\n로고 스케치에는 녹색 나뭇잎으로 재활용 심볼을 만들고, 심볼 아래에 녹색 또는 갈색과 같은 지구 톤 색조의 굵은 연도 글꼴로 웹사이트 이름을 넣을 수 있습니다. 또 다른 가능성은 지구를 나타내는 지구본을 재활용 화살표가 녹색 또는 파란색의 대조적인 색조로 감싸고 있는 지구본을 사용하는 것입니다.\\n\\n텍스트는 균형 잡히고 매력적이며 명확하고 가독성이 있어야 합니다. 선호하는 글꼴은 몬세라트 또는 오픈 산스와 같은 산세리프체일 수 있지만, 이 옵션은 웹사이트 이름에 따라 달라집니다. 최종 결과는 재활용 웹사이트의 가치를 반영하는 깔끔하고 현대적이며 알아볼 수 있는 로고여야 합니다.',\n",
              " '대공황은 1929년부터 1939년까지 지속된 경제 침체기로, 현대 역사상 가장 오래 지속된 불황입니다. 대공황은 미국뿐만 아니라 전 세계 국가에 영향을 미쳐 상당한 사회적, 경제적 격변을 일으켰습니다.\\n\\n대공황에는 다음과 같은 몇 가지 주요 원인이 있었습니다:\\n\\n1. 1929년 주식 시장 붕괴 - 1929년 10월, 주식 시장이 크게 하락하여 수백만 명의 투자자가 목숨을 잃었습니다. 이 사건은 많은 사람들이 대공황의 초기 방아쇠를 당긴 사건으로 간주합니다.\\n\\n2. 과잉 생산 - 1920년대에는 많은 산업에서 소비자가 원하거나 감당할 수 있는 것보다 더 많은 상품을 생산했습니다. 이는 궁극적으로 상품에 대한 수요 감소로 이어져 일자리 감소, 임금 하락, 사업 실패를 초래했습니다.\\n\\n3. 높은 관세와 전쟁 부채 - 높은 관세 형태의 보호주의 무역 정책은 다른 국가들이 자체 관세로 보복하면서 세계 무역의 감소로 이어졌습니다. 또한 많은 국가들이 전쟁 부채 상환에 어려움을 겪으면서 경제가 불안정해졌습니다.\\n\\n4. 은행 부실 - 상품에 대한 수요가 감소하면서 많은 은행이 파산하기 시작했고, 은행 시스템에 대한 신뢰가 떨어졌습니다. 이로 인해 은행에서 대규모 자금 인출이 발생하여 더 많은 은행이 도산했습니다.\\n\\n5. 가뭄 상황 - 더스트 보울은 1930년대 미국 대평원 지역을 강타한 극심한 가뭄과 먼지 폭풍이었습니다. 이는 농업에 큰 영향을 미쳐 많은 농부들이 토지와 생계를 잃게 되었고, 이는 대공황의 영향을 더욱 악화시켰습니다.\\n\\n전반적으로 대공황은 경제적, 환경적, 정치적 요인을 포함한 복합적인 요인으로 인해 발생했습니다. 그 영향은 광범위하게 퍼져 전 세계 수백만 명의 사람들에게 영향을 미쳤습니다.',\n",
              " '데이터 개인정보 보호 문제에 대한 한 가지 윤리적 해결책은 기업이 사용자 데이터를 수집, 저장, 사용하는 방법을 투명하게 공개하도록 요구하는 엄격한 규정과 표준을 시행하는 것입니다. 즉, 기업은 사용자로부터 어떤 데이터를 수집하는지, 왜 이 데이터가 필요한지, 어떻게 사용할 계획인지 명시적으로 밝혀야 합니다. 또한 사용자는 언제든지 자신의 데이터에 액세스하고, 수정하고, 삭제할 수 있는 권리를 갖게 됩니다.\\n\\n또한 기업은 무단 액세스 및 침해로부터 사용자 데이터를 보호하기 위해 강력한 보안 조치를 우선적으로 구현해야 합니다. 여기에는 암호화, 다단계 인증, 정기적인 보안 감사 등의 조치가 포함될 수 있습니다. 데이터 유출이 발생한 경우 기업은 책임을 져야 하며 영향을 받은 사용자에게 적시에 알려야 합니다.\\n\\n또한 사용자는 자신의 데이터와 개인정보 보호에 대해 정보에 입각한 결정을 내릴 수 있는 권한을 부여받아야 합니다. 이는 데이터 개인정보 보호에 대한 인식을 높이고 개인이 온라인에서 개인정보를 더 잘 관리할 수 있도록 도와주는 도구와 리소스를 제공함으로써 달성할 수 있습니다.\\n\\n궁극적으로 데이터 프라이버시 보호는 기업과 사용자가 공동으로 책임져야 합니다. 기업은 사용자 데이터를 보호하기 위해 최선을 다해야 하며, 사용자는 자신의 개인정보를 보호하기 위해 적극적인 역할을 수행해야 합니다. 서로 협력함으로써 보다 안전하고 윤리적인 데이터 환경을 조성할 수 있습니다.',\n",
              " '특이한 것은 텔레그램입니다. 트위터와 인스타그램은 주로 정보, 이미지, 동영상을 공유하는 소셜 미디어 플랫폼인 반면, 텔레그램은 클라우드 기반 인스턴트 메시징 및 VoIP 서비스입니다.',\n",
              " '문장에 철자 오류가 두 개 있습니다. 수정된 문장은 다음과 같아야 합니다: \"그는 식사를 마치고 식당을 떠났다.\"',\n",
              " '두더지가 지하에 사는 동물인 것은 사실이지만, 이 정의는 불완전하며 두더지의 특징이나 생물학적 분류를 적절히 설명하지 않아 오해를 불러일으킬 수 있습니다. 두더지는 두더지과에 속하는 포유류로, 몸집이 작고 땅을 파며 식충성 동물입니다. 두더지는 원통형의 몸, 짧은 팔다리, 작은 눈과 귀로 잘 알려져 있습니다. 이 정의는 또한 화학에서 사용되는 측정 단위를 나타내는 화학 용어인 두더지와 동물을 구분하지 않습니다. 이러한 이유로 주어진 두더지의 정의는 완전히 정확하거나 명확하게 설명하지 못합니다.',\n",
              " '단어 임베딩은 어휘집의 단어나 구를 실수 벡터에 매핑하는 데 사용되는 자연어 처리 기법의 일종입니다. 단어 사이의 유사성을 해당 벡터 사이의 거리로 측정할 수 있는 연속 벡터 공간에 단어를 표현하는 것이 이 기법의 핵심입니다. 이 작업은 Word2Vec 또는 GloVe와 같은 알고리즘을 사용하여 수행할 수 있습니다.\\n\\n단어 임베딩을 사용하면 컴퓨터가 단순히 개별 단어의 유무를 보는 것보다 훨씬 더 의미 있는 방식으로 텍스트를 이해할 수 있기 때문에 자연어 처리 분야에 혁명을 일으켰습니다. 예를 들어, 단어 임베딩을 사용하면 컴퓨터는 \"개\"와 \"강아지\"라는 단어는 밀접한 관련이 있지만 \"개\"와 \"우산\"이라는 단어는 그렇지 않다는 것을 이해할 수 있습니다.\\n\\n단어 임베딩은 텍스트 분류, 감성 분석, 기계 번역, 명명된 개체 인식 등 다양한 자연어 처리(NLP) 작업에 사용됩니다. 단어 임베딩은 딥 러닝 및 신경망 기계 번역과 같은 많은 고급 언어 처리 기술의 기초를 형성합니다.',\n",
              " '\"워털루는 벨기에 중부의 작은 도시로 유럽 역사에서 중추적인 역할을 한 곳으로 유명합니다. 1815년, 이곳은 나폴레옹 보나파르트의 프랑스 황제 통치를 종식시킨 역사적인 전투인 워털루 전투가 벌어진 곳입니다.\\n\\n이 도시의 기원은 중요한 교차로 정착지였던 로마 시대로 거슬러 올라갑니다. 중세 시대에 워털루는 번영한 무역과 산업의 중심지였으며 양모와 직물 생산으로 유명했습니다.\\n\\n18세기에는 그림 같은 풍경과 스파 리조트에 매료된 부유한 귀족들이 즐겨 찾는 곳이 되었습니다. 하지만 워털루가 역사의 기록에 영원히 새겨진 것은 19세기, 1815년 6월 18일 나폴레옹 보나파르트 군대와 유럽 열강 연합군이 도시를 둘러싼 들판에서 충돌한 사건입니다.\\n\\n워털루 전투는 유럽 역사상 가장 유혈이 낭자하고 결정적인 전투 중 하나였습니다. 프랑스군은 패배했고 나폴레옹은 강제로 망명길에 올랐어요. 이 전투로 유럽 대륙에서 25년에 걸친 전쟁이 종식되었고, 제1차 세계대전이 발발할 때까지 지속된 상대적 평화의 시대가 열렸습니다.\\n\\n오늘날 워털루는 인구 약 30,000명의 조용한 도시입니다. 전장과 역사적인 전투를 기념하는 많은 기념물과 박물관을 방문하러 오는 역사 애호가들에게 인기 있는 여행지입니다.\"',\n",
              " '식물의 세포 호흡은 포도당을 세포의 주 에너지원으로 사용되는 분자인 ATP로 전환하는 과정입니다. 이 과정은 동물의 과정과 유사하며 다양한 효소 반응이 수반됩니다.\\n\\n식물에서 세포 호흡은 일반적으로 미토콘드리아에서 이루어지며, 이 과정은 해당 과정, 구연산 주기(크렙스 주기라고도 함), 전자 수송 사슬의 세 단계로 나눌 수 있습니다.\\n\\n해당 과정에서 포도당 한 분자는 두 개의 피루브산 분자로 분해됩니다. 이 과정은 세포의 세포질에서 일어나며 두 분자의 ATP와 두 분자의 전자를 운반하는 분자인 NADH를 생성합니다.\\n\\n다음 단계인 구연산 순환은 미토콘드리아 내부에서 일어납니다. 여기서 해당 작용에서 생성된 두 개의 피루브산 분자가 더 분해되어 ATP, NADH, 그리고 전자를 운반하는 또 다른 분자인 FADH2를 생성합니다.\\n\\n마지막으로, 전자 전달 사슬에서 이전 단계에서 생성된 NADH와 FADH2 분자는 미토콘드리아 내막에 내장된 일련의 단백질 복합체에 전자를 전달합니다. 이 전자는 막을 가로지르는 양성자의 흐름을 생성하여 화학 삼투압으로 알려진 과정을 통해 ATP 생성을 유도하는 구배를 만듭니다.\\n\\n요약하면, 식물의 세포 호흡은 포도당을 분해하여 세포의 주요 에너지원으로 사용되는 ATP를 생성하는 과정입니다. 이 과정은 미토콘드리아에서 일어나며 해당 과정, 구연산 주기 및 전자 수송 사슬을 포함한 여러 단계를 포함합니다.',\n",
              " '텍스트의 어조는 진지하고 침울합니다. \"크게 영향을 받다\", \"급격하게 변화하다\", \"팬데믹\" 등의 용어를 사용하여 상황의 심각성과 중대성을 암시하고 무겁고 우려스러운 느낌을 전달합니다.',\n",
              " '코깅 토크는 고정자(전기 모터 또는 발전기의 고정 부품)와 회전자(회전 부품)의 자기장 사이의 상호 작용에 의해 생성되는 토크를 말합니다. 이 상호 작용은 고정자 톱니와 회전자 극 사이에 자기 인력을 생성합니다. 이 시나리오는 고르지 않은 토크로 이어져 모터가 부드럽게 회전하는 대신 갑작스러운 동작을 경험하게 합니다.\\n\\n코깅 토크는 주로 회전자 및 고정자 권선의 회전 수가 많은 모터와 모터에 작은 공극이 있는 모터에서 발생합니다. 고정자 또는 회전자 슬롯을 기울이거나 고정자 및 회전자 슬롯의 수를 적절히 선택하면 코깅 효과를 줄일 수 있습니다. 적절한 설계는 코깅 토크를 줄여 부드럽고 지속적인 회전을 가능하게 합니다.',\n",
              " \"주어진 방정식은 변수가 있는 항을 분리하거나 모든 항을 방정식의 한쪽으로 이동하여 0과 같게 만드는 방법으로 대수식으로 변환할 수 있습니다. 다음은 두 가지 옵션입니다:\\n\\n1. 변수가 있는 항을 분리합니다:\\n- 양쪽에서 5y를 빼서 상수 항을 방정식의 오른쪽으로 옮길 수 있습니다. 이렇게 하면 대수식이 됩니다:\\n\\n3x = 9 - 5y\\n\\n- 또는 x와 관련된 항을 방정식의 오른쪽으로 이동하여 y를 분리할 수도 있습니다. 양쪽에서 3x를 빼면 다음과 같이 됩니다:\\n\\n5y = 9 - 3x\\n\\n2. 모든 항을 한쪽으로 이동하여 0과 같게 만듭니다:\\n- 방정식의 양쪽에서 9를 빼면 됩니다.\\n\\n이렇게 하면 대수식이 됩니다:\\n3x + 5y - 9 = 0입니다.\\n\\n전반적으로 원래의 방정식 '3x+5y=9'는 특정 요구 사항이나 상황에 따라 여러 가지 다른 등가 형태로 표현할 수 있습니다.\",\n",
              " '1. 학교와 학생 모두에게 온라인 교육에 대한 인기가 높아지고 있습니다.\\n2. 온라인 교육의 장점은 저렴한 비용과 적은 노력입니다.\\n3. 온라인 교육을 통해 학생들은 자신에게 맞는 시간, 장소, 속도로 공부할 수 있습니다.',\n",
              " '쿠바 미사일 위기(1962년)와 베트남 전쟁(1955~1975년)은 냉전 시대에 발생한 미국 역사에서 중요한 두 사건입니다. 두 사건 모두 미국과 공산권 간의 긴장이 고조된 것이 특징이지만, 두 사건에는 몇 가지 중요한 차이점이 있습니다.\\n\\n쿠바 미사일 위기는 미국 해안에서 불과 90마일 떨어진 쿠바에 소련의 핵미사일을 설치하는 문제로 미국과 소련이 13일간 정치적, 군사적으로 대치한 사건입니다. 이와는 대조적으로 베트남 전쟁은 미국, 남베트남, 북베트남 및 기타 공산주의 동맹국이 참여한 거의 20년 동안 지속된 장기적인 분쟁이었습니다. 이 전쟁은 미국이 동남아시아에서 공산주의의 확산을 막으려는 시도의 결과였습니다.\\n\\n쿠바 미사일 위기는 미국과 소련이 전면적인 대결 직전까지 치달으면서 세계가 핵전쟁에 가장 근접했던 사건으로 꼽히기도 합니다. 결국 소련이 쿠바를 침공하지 않겠다는 미국의 약속과 터키에 배치된 미국 미사일을 철거하기로 비밀리에 합의하는 대가로 쿠바에서 미사일을 철거하는 데 동의하면서 평화적인 해결에 도달했습니다. 이와는 대조적으로 베트남 전쟁은 수백만 명의 목숨을 잃고 수많은 부상자가 발생했으며 광범위한 사회 기반 시설이 파괴되는 등 막대한 피해를 가져왔습니다.\\n\\n두 사건의 또 다른 주요 차이점은 국내 지원이었습니다. 쿠바 미사일 위기 당시에는 미국 정부의 조치에 대한 대중의 광범위한 지지가 있었으며, 케네디 대통령의 상황 대처는 종종 그의 가장 큰 업적 중 하나로 꼽힙니다. 그러나 베트남 전쟁은 미국 대중에게 큰 인기를 얻지 못했고 반전 정서는 수년에 걸쳐 꾸준히 커졌습니다. 전쟁으로 인해 미국 정부와 군에 대한 신뢰가 크게 떨어졌고, 베트남 전쟁은 미국 역사상 가장 분열적인 분쟁 중 하나로 여전히 기억되고 있습니다.\\n\\n결론적으로 쿠바 미사일 위기와 베트남 전쟁은 둘 다 냉전의 주요 사건이었지만 기간, 결과, 국내 지원 측면에서 차이가 있습니다. 쿠바 미사일 위기는 짧고 격렬했던 대치 상황이 평화적으로 해결된 반면, 베트남 전쟁은 장기간에 걸친 분쟁으로 광범위한 피해가 발생했고 국내적으로도 큰 반향을 불러일으켰습니다.',\n",
              " '한바탕 웃음과 응원의 함성\\n우리가 소중히 간직하는 기쁨의 순간들\\n믿음의 도약, 활짝 웃는 미소\\n내면에서 피어나는 따뜻한 느낌\\n\\n밝게 빛나는 태양, 너무 푸른 하늘\\n다채로운 세상, 멋진 경치\\n꼭 껴안는 포옹, 친절한 말 한마디\\n행복한 마음, 평화로운 마음\\n\\n리듬에 맞춰 춤을 추고 큰 소리로 노래하기\\n군중 속에서 돋보이는 나 자신\\n우리를 빛나게하는 작은 것들을 포용하십시오.\\n그리고 내면의 기쁨이 넘쳐나도록\\n\\n행복은 장소가 아니라 여정입니다.\\n마음의 상태, 그냥 자유롭게 두십시오.\\n어디를 가든 기쁨을 전파해\\n세상은 찬란한 빛으로 빛날 거야.',\n",
              " '소피는 책상에 앉아 컴퓨터 화면을 멍하니 바라보고 있었습니다. 눈앞에 놓인 선택지를 놓고 고민하는 그녀의 머릿속은 복잡했습니다. 회사에서 고위 관리직으로 승진하라는 제안을 받았지만, 이는 친구와 가족을 뒤로한 채 전국을 돌아다니며 이사해야 한다는 것을 의미했습니다. 동시에 꿈에 그리던 라이벌 회사의 일자리가 마침내 열렸고 면접에 초대받았습니다.\\n\\n편안한 삶을 뒤로하고 새롭고 불확실한 것에 도전한다는 생각에 소피는 불안하면서도 설레는 마음이 들었습니다. 소피는 항상 위험을 감수하는 편이었고, 과거에도 그런 도전이 성과를 거둔 적이 있었습니다. 하지만 이제 큰 결정을 내려야 하는 상황에서 소피는 부담감을 느낄 수밖에 없었습니다.\\n\\n많은 고민 끝에 소피는 선택을 했습니다. 그녀는 짐을 싸서 사랑하는 사람들과 작별 인사를 하고 새로운 직장을 찾아 미국 전역으로 이사했습니다. 새로운 도시와 새로운 회사 문화에 적응하느라 처음 몇 달은 힘들었습니다. 하지만 시간이 지나면서 소피는 자신의 커리어를 위해 최선의 결정을 내렸다는 것을 깨달았습니다. 업무는 도전적이었지만 보람도 컸고, 열정적이고 추진력 있는 동료들에게 둘러싸여 성장하고 발전할 수 있는 영감을 얻었습니다.\\n\\n결국 소피의 대담한 결정은 결실을 맺었습니다. 그녀는 새로운 역할에서 번창하고 있었고, 새로운 도시에서 새로운 친구와 인맥을 쌓았습니다. 돌이켜보면 소피는 위험을 감수하고 변화를 시도할 수 있는 기회에 감사했고, 자신의 커리어를 위해 올바른 결정을 내렸다는 확신을 가졌습니다.',\n",
              " '일반적으로 AI로 알려진 인공 지능은 기본적으로 인간의 지능이 필요한 작업을 수행할 수 있는 컴퓨터 시스템을 개발하는 것입니다. 이러한 작업에는 언어 번역, 의사 결정, 시각 인식, 음성 인식, 심지어 복잡한 전략 게임까지 포함될 수 있습니다.\\n\\n간단히 말해, AI는 컴퓨터와 기계가 사고, 추론, 문제 해결과 같이 일반적으로 인간만이 할 수 있는 일을 할 수 있는 것입니다. 이는 컴퓨터가 스스로 학습하고 데이터를 기반으로 의사 결정을 내리는 데 도움이 되는 알고리즘 또는 규칙 집합을 생성함으로써 달성됩니다.\\n\\n전반적으로 AI는 컴퓨터가 이전에는 불가능하다고 여겨졌던 방식으로 학습하고 적응하며 개선할 수 있게 해주는 매혹적이고 강력한 기술입니다.',\n",
              " '화씨 온도는 59.0도입니다. (°F = °C * 9/5 + 32)',\n",
              " '삼림 벌채 또는 삼림 지역에서 나무를 대규모로 제거하는 행위는 환경, 경제 및 지역 사회에 중대한 영향을 미칠 수 있는 여러 가지 결과를 초래합니다. 삼림 벌채의 결과 중 일부는 다음과 같습니다:\\n\\n1. 생물 다양성 손실: 숲에는 다양한 동식물이 서식하고 있으며, 이들 중 상당수는 생존을 위해 숲에 의존하고 있습니다. 넓은 면적의 나무를 제거하면 서식지가 파괴되어 생물 다양성이 손실될 수 있습니다.\\n\\n2. 토양 침식: 나무와 나무의 뿌리 시스템은 토양을 제자리에 고정하고 침식을 방지하는 데 도움이 됩니다. 삼림 벌채로 인해 토양이 노출되어 폭우나 강풍에 휩쓸리기 쉬워질 수 있습니다.\\n\\n3. 기후 변화: 산림은 이산화탄소를 저장하여 지구의 기후를 조절하는 데 중요한 역할을 합니다. 나무가 제거되면 저장된 이산화탄소가 대기 중으로 방출되어 기후 변화에 기여합니다.\\n\\n4. 생계 수단의 상실: 많은 원주민과 지역 사회는 연료, 건축 자재, 식량으로 나무를 사용하는 등 생계를 위해 숲에 의존하고 있습니다. 삼림 벌채는 이러한 지역사회에 치명적인 영향을 미쳐 자원이나 자립 수단을 잃게 만들 수 있습니다.\\n\\n5. 경제적 영향: 산림은 목재, 종이, 기타 임산물 등 다양하고 가치 있는 자원을 제공합니다. 삼림 벌채는 이러한 자원의 가용성을 감소시켜 자원에 의존하는 경제와 산업에 영향을 미칠 수 있습니다.\\n\\n6. 홍수: 산림은 물을 흡수하고 저장하여 인근 지역의 홍수 위험을 줄여줍니다. 삼림 벌채는 홍수 위험을 증가시켜 주택, 인프라, 농작물에 피해를 입힐 수 있습니다.\\n\\n전반적으로 삼림 벌채는 환경뿐만 아니라 경제와 지역 사회에도 영향을 미치는 광범위한 부정적 영향을 미칠 수 있습니다. 삼림 벌채와 그로 인한 결과를 방지하기 위해 지속 가능한 산림 자원 관리 방법을 찾는 것이 중요합니다.',\n",
              " '다음은 10개의 무작위 단어 목록입니다:\\n\\n1. 퀴블\\n2. Avarice\\n3. 꾸미다\\n4. 공명\\n5. 머큐리얼\\n6. Conflagration\\n7. 지칠 줄 모르는\\n8. 장난꾸러기\\n9. 묘사하다\\n10. Paragon',\n",
              " \"원의 넓이를 구하는 공식은 A = πr^2이며, 여기서 'A'는 원의 넓이, 'r'은 반지름입니다. 주어진 반지름 값을 공식에 대입합니다:\\n\\nA = π(4^2)\\nA = 16π\\n\\n따라서 반지름이 4 단위인 원의 넓이는 16π 제곱 단위입니다.\",\n",
              " '1. 용기\\n2. 두려움 없는\\n3. 대담한\\n4. 용감한\\n5. Intrepid\\n6. Daring\\n7. Unflinching\\n8. Undaunted\\n9. Resolute\\n10. Gallant\\n11. Plucky\\n12. 영웅적\\n13. 사자 마음\\n14. 강인한 마음\\n15. 대담한.',\n",
              " '이 구절은 지구 기후 변화의 중요성을 강조하는 한 연구에 대해 설명합니다. 이어서 해수면 상승과 생물 다양성 손실과 같은 결과에 대해 언급합니다. 기후 변화는 인간의 활동으로 인해 발생하며, 해결하지 않으면 장기적으로 파괴적인 영향을 미칠 가능성이 있습니다.',\n",
              " '1. 산업 배출 규제: 정부는 산업계에 대한 엄격한 규제를 시행하여 수역으로 배출되는 화학물질과 오염물질의 양을 통제하고 줄여야 합니다.\\n\\n2. 친환경 농업 장려: 농부들이 수질 오염을 줄이기 위해 친환경 농법을 사용하도록 장려해야 합니다. 여기에는 비료와 살충제 사용을 줄이고 해충을 방제하기 위해 자연적인 방법을 사용하는 등의 조치가 포함될 수 있습니다.\\n\\n3. 대중의 인식을 높입니다: 수질 오염의 위험성과 이를 줄이기 위해 개인이 취할 수 있는 조치에 대한 대중의 인식 제고 캠페인이 확대되어야 합니다. 유해한 생활 쓰레기를 올바르게 처리하고, 일회용 플라스틱 사용을 줄이고, 물을 절약하는 등의 간단한 행동만으로도 수질 오염을 줄이는 데 큰 도움이 될 수 있습니다.\\n\\n4. 하수 및 폐수 처리 개선: 정부는 하수 및 폐수 처리 시설을 개선하는 데 투자하여 수역으로 배출되기 전에 폐기물에서 오염 물질을 효율적이고 효과적으로 제거할 수 있도록 해야 합니다.\\n\\n5. 친환경 에너지 장려: 태양열 및 풍력과 같은 친환경 에너지원을 사용하면 화석 연료가 수역으로 방출하는 오염 물질의 양을 줄일 수 있습니다. 정부는 개인과 산업체가 친환경 에너지원으로 전환하도록 인센티브를 제공해야 합니다.\\n\\n6. 수질 모니터링: 강, 호수, 바다의 수질을 정기적으로 모니터링하면 오염원을 파악하고 오염을 줄이기 위한 적절한 조치를 취하는 데 도움이 될 수 있습니다.\\n\\n7. 정화 및 복원: 정부는 오염된 수역을 정화하고 자연 생태계를 복원하는 데 투자해야 합니다. 여기에는 오염 물질 제거, 침식 방지를 위한 초목 심기, 토종 종 재도입 등의 조치가 포함될 수 있습니다.\\n\\n8. 환경법 강화 및 시행: 강력한 환경 법규와 엄격한 집행은 수질 오염을 줄이는 데 도움이 될 수 있습니다. 정부는 위반자를 처벌하고 법이 수자원 보호에 효과적일 수 있도록 조치를 취해야 합니다.',\n",
              " \"찰스 2세는 1660년부터 1685년까지 잉글랜드, 스코틀랜드, 아일랜드의 군주였습니다. 1630년 5월 29일에 태어난 그는 찰스 1세와 헨리에타 마리아 여왕의 아들이었습니다. 아버지의 통치 기간 동안 영국은 왕정을 지지하는 왕당파와 왕권을 제한하려는 의회주의자 간의 내전에 휩싸였습니다. 결국 올리버 크롬웰이 이끄는 의회주의자들이 승리를 거두었고 찰스 1세는 1649년 처형당했습니다.\\n\\n찰스 2세는 망명길에 올라 프랑스와 네덜란드에서 한동안 살았습니다. 1660년 크롬웰이 사망하고 영연방 정부가 붕괴한 후 찰스는 영국으로 초대되어 왕위에 복귀했습니다.\\n\\n종종 왕정복고라고 불리는 그의 통치는 상대적으로 안정과 번영의 시기로 특징지어집니다. 찰스는 영국 국교회를 국가 교회로 재건하고 내전의 폐허를 딛고 국가를 재건하기 위해 노력했습니다. 또한 종교적 관용 정책을 추구하여 1672년 성공회가 아닌 개신교 신자들에게 예배의 자유를 허용하는 '면죄부 선언'을 발표했습니다.\\n\\n찰스는 과학과 예술에 대한 관심으로도 유명했는데, 1660년에 설립된 과학 단체인 왕립 학회의 후원자였습니다. 그의 궁정은 사치와 쾌락주의로 유명했으며 찰스 자신도 여성 혐오자로 명성이 높았습니다.\\n\\n재위 말기에 찰스는 특히 친가톨릭 정책과 의회의 권위를 우회하려는 시도로 인해 의회의 반대에 직면했습니다. 1678년에는 모든 공직자가 가톨릭에 반대하는 선서를 하도록 하는 '시험법'이 통과되었고 찰스는 마지못해 서명했습니다.\\n\\n찰스는 1685년 2월 6일에 사망했고, 그의 동생 제임스 2세가 왕위를 계승했습니다. 그는 혼란의 시기 이후 영국의 안정을 회복하는 데 도움을 준 인기 있고 카리스마 넘치는 군주로 기억되고 있습니다.\",\n",
              " '1. 현재 전기 사용량을 분석합니다: 월 평균 청구서를 포함하여 가정의 현재 전기 사용량에 대한 데이터를 수집하고 전기를 가장 많이 소비하는 가전제품과 장치를 식별하는 것으로 시작하세요.\\n\\n2. 비효율적인 가전제품을 교체하세요: 오래되고 에너지 효율이 낮은 가전제품을 동일한 기능을 제공하면서 전력 소비가 적은 ENERGY STAR 인증 가전제품으로 업그레이드하거나 교체하세요.\\n\\n3. LED 조명 사용: 기존 전구를 최대 75% 더 적은 에너지를 사용하고 최대 25배 더 오래 사용할 수 있는 에너지 효율이 높은 LED 전구로 교체합니다.\\n\\n4. 사용하지 않을 때는 기기 플러그를 뽑아둡니다: 충전기, TV, 컴퓨터 등 많은 전자 기기는 전원이 꺼져 있어도 전력을 소비합니다. 사용하지 않는 기기의 플러그를 뽑아 전력 소비를 줄이세요.\\n\\n5. 스마트 멀티탭 사용: 사용하지 않는 기기의 전원을 자동으로 차단하여 대기 전력 소비를 줄여주는 스마트 멀티탭 사용을 고려하세요.\\n\\n6. 온도 조절기 조정: 난방과 냉방은 가정 전체 에너지 소비의 최대 절반을 차지할 수 있습니다. 집에 아무도 없을 때나 야간에 난방 또는 냉방 사용량을 줄이려면 온도 조절기를 조정하고 프로그래밍 가능 또는 스마트 온도 조절기를 사용하세요.\\n\\n7. 웨더 스트리핑을 설치합니다: 문과 창문 주변에 웨더스트립을 설치하여 공기가 새는 것을 방지하여 냉난방 시스템의 부하를 줄이세요.\\n\\n8. 자연 채광을 이용합니다: 낮에는 블라인드와 커튼을 열고 인공 조명 사용을 자제하여 가능한 한 자연광을 활용하세요.\\n\\n9. 에너지 절약 행동을 장려합니다: 외출 시 전등 끄기, 샤워 시간 짧게 하기, 식기 세척기와 세탁기가 가득 찼을 때만 작동하기 등 에너지 절약 습관에 대해 가족 구성원에게 교육하세요.\\n\\n10. 전기 사용량을 정기적으로 모니터링하세요: 정기적으로 전기 사용량을 추적하고 그 결과에 따라 에너지 절약 계획을 조정합니다.',\n",
              " '배달 회사 앱은 고객이 한 곳에서 모든 배달 요구 사항을 효율적으로 관리할 수 있는 방법을 제공합니다. 이 앱의 주요 기능은 다음과 같습니다:\\n\\n1. 사용자 계정: 고객은 개인 계정을 생성하여 배달 주문을 추적하고 계정 내역을 볼 수 있습니다. 계정을 통해 개인 정보, 연락처 세부 정보 및 주소를 수정할 수 있습니다.\\n\\n2. 주문 배치: 고객은 원하는 품목을 선택하거나 쇼핑 목록의 이미지를 업로드하여 앱에서 배달 주문을 할 수 있습니다. 주문은 특정 날짜와 시간으로 예약하거나 반복적으로 주문할 수 있습니다.\\n\\n3. 실시간 추적: 고객은 도착 예정 시간에 대한 업데이트와 함께 지도에서 실시간으로 주문을 추적할 수 있습니다.\\n\\n4. 인앱 커뮤니케이션: 고객은 앱 내 채팅 기능을 통해 배송 지침, 일정 또는 특별 요청에 대해 배송 기사와 소통할 수 있습니다.\\n\\n5. 배송 확인: 배송이 완료되면 고객에게 알림이 전송되며, 고객은 배송을 확인하고 서비스를 평가할 수 있습니다.\\n\\n6. 결제: 고객은 신용카드나 모바일 결제 시스템 등 선호하는 결제 수단을 앱에 추가할 수 있으며, 거래가 원활하게 처리됩니다.\\n\\n7. 고객 지원: 고객은 헬프 센터에 액세스하여 문제를 신고하고 질문에 대한 답변을 얻거나 앱에서 직접 고객 지원팀에 전화할 수 있습니다.\\n\\n전반적으로 이 배달 앱은 고객에게 직관적이고 사용자 친화적인 인터페이스를 제공하여 배송 프로세스를 원활하고 스트레스 없이 진행할 수 있습니다.',\n",
              " '중력으로 인해 1kg의 질량에 가해지는 힘은 약 9.8뉴턴입니다. 이는 F = mg 공식을 사용하여 계산되며, 여기서 F는 힘, m은 질량, g는 중력으로 인한 가속도입니다. 지구 표면에서 g의 대략적인 값은 9.8m/s^2입니다. 따라서 중력으로 인해 1kg의 질량에 가해지는 힘은 1kg * 9.8m/s^2 = 9.8N입니다.',\n",
              " '문화적 관습의 한 예로 일본의 전통 다도인 차노유를 들 수 있습니다. 이 의식에는 가루 녹차인 말차를 준비하고 올리는 과정이 포함됩니다. 차노유는 일본 문화에 깊이 뿌리내린 의식으로 조화, 존중, 순결, 평온의 원칙을 중심으로 진행됩니다. 이 의식은 단순히 차를 마시는 것이 아니라 차의 미학과 준비, 호스트와 손님 간의 상호 작용, 그리고 그 순간에 대한 감상에 관한 것입니다.',\n",
              " '집합 {10, 3, 25, 6, 16}의 최대값은 25입니다.',\n",
              " '6과 2의 곱은 12입니다.',\n",
              " '제가 책을 샀습니다.',\n",
              " '스컹크 양배추(심플로카르푸스 포에티두스)는 북미 동부의 습지, 늪지, 하천변에 자생하는 다년생 저성장 식물입니다. 스컹크 냄새와 비슷하다고 알려진 독특하고 매운 냄새 때문에 이름이 붙여졌습니다. 이 식물은 크고 넓은 잎을 가지고 있으며 후드 모양의 주걱으로 둘러싸인 다육질의 꽃받침에 작은 꽃을 피웁니다. 스컹크 양배추는 천남성과에 속하며, 여기에는 필로덴드론과 평화 백합과 같은 식물도 포함됩니다.',\n",
              " '이진수 101101은 소수점 45에 해당합니다.',\n",
              " '사막 생물군계에는 덥고 건조한 사막과 추운 사막의 두 가지 유형이 있습니다.',\n",
              " '이 구절의 주요 내용은 기후 변화가 기상이변과 해수면 상승을 통해 환경과 인류의 삶에 심각한 영향을 미치는 중요한 글로벌 문제라는 것입니다.',\n",
              " '골목 고양이가 개에게 짖었습니다.',\n",
              " '다음은 액체의 두 가지 예입니다:\\n\\n1. 물: 물은 모든 형태의 생명체에 필수적인 투명하고 무색, 무취의 액체입니다. 물은 호수, 강, 바다, 심지어 지하에도 존재합니다.\\n\\n2. 기름: 오일은 석유에서 추출한 점성이 있는 액체입니다. 일반적으로 운송 및 제조와 같은 다양한 산업에서 연료 또는 윤활유로 사용됩니다.',\n",
              " '\"하드\"는 이 문장에 가장 적합한 부사입니다. 완전한 문장은 다음과 같습니다: \"그녀는 열심히 일한다.\"',\n",
              " '그는 책을 읽고 있습니다.',\n",
              " '\"그녀의 눈은 밝은 별처럼 설렘과 경이로움으로 반짝였습니다.\"',\n",
              " '\"나는 지금 당신에게 너무 화가 났어요\"라는 문장의 어조는 화가 나고 좌절감을 나타냅니다.',\n",
              " '사람 1: 수력 발전에 대해 들어보셨나요?\\n\\n사람 2: 네, 흐르는 물의 에너지를 이용해 전기를 생산하는 거죠?\\n\\n사람 1: 네, 맞아요! 물의 운동 에너지가 전기 에너지로 변환되는 것이죠.\\n\\n사람2: 아, 그러니까 물이 댐을 넘어가서 터빈을 돌리면 그것도 전기를 만드는 거군요.\\n\\n사람 1: 수력 발전이 작동하는 한 가지 방법이지만, 수력 발전을 위해 사용할 수 있는 다른 방법도 많이 있습니다. 예를 들어 해안 지역에서는 밀물과 썰물에서 나오는 에너지를 활용하는 조력 발전소를 건설할 수 있습니다.\\n\\n사람 2: 놀랍네요! 그건 몰랐어요. 수력 발전도 지속 가능하고 환경 친화적인 에너지원인 것 같네요.\\n\\n사람 1: 네, 수력발전은 오염을 최소화하고 온실가스 배출을 줄이는 데 도움이 되는 재생 에너지원이에요. 하지만 댐을 건설하는 데는 비용이 많이 들고 지역 생태계를 교란할 수 있다는 단점이 있죠.\\n\\n사람 2: 네, 그런 것 같아요. 하지만 장점은 분명 단점보다 크며, 수력 발전을 통해 전기를 생산하는 새로운 방법을 계속 개발하고 탐구할 수 있다면 좋을 것 같아요.\\n\\n사람 1: 물론이죠, 수력 발전은 전기 생산뿐만 아니라 효율적인 물 관리에도 도움이 됩니다. 수력을 제대로 활용한다면 전 세계 에너지 위기에 대한 해답이 될 수 있을 겁니다.',\n",
              " '죄송하지만 John이라는 사람에 대한 추가 정보가 없는 한 이 사람에 대한 설명을 생성할 수 없습니다. John은 일반적인 이름이며 이 이름을 가진 사람이 많을 수 있습니다. 더 정확한 설명을 만들 수 있도록 나이, 직업 또는 기타 개인 정보와 같은 자세한 정보를 제공해 주실 수 있나요?',\n",
              " '마리아는 사과가 21개 있는데 친구 4명에게 똑같이 나누고 싶습니다. 각 친구는 몇 개의 사과를 받게 되며, 남은 사과는 몇 개가 될까요?',\n",
              " '기후 변화는 기온 상승, 기상 이변의 빈도와 강도 증가, 야생동물과 생태계에 대한 부정적인 영향 등 지구에 광범위하고 파괴적인 영향을 미치는 글로벌 문제입니다. 주로 화석 연료의 연소로 인해 이산화탄소, 메탄, 아산화질소 등 유해한 오염 물질이 대기 중으로 방출되어 발생합니다. 이러한 온실가스는 태양열을 가두어 대기 중 농도가 높아지면 지구의 온도도 상승합니다.\\n\\n기후 변화에 대응하기 위해서는 화석 연료에서 벗어나 대체 에너지원으로 전환하는 것이 필수적입니다. 태양열, 풍력, 수력, 지열과 같은 대체 에너지원은 화석 연료가 아닌 재생 가능한 에너지원으로 전기를 생산하므로 온실가스 배출량이 훨씬 적습니다. 이러한 청정 에너지원을 사용하여 탄소 발자국을 줄임으로써 지구의 온난화를 방지하고 기후 변화의 유해한 영향을 완화할 수 있습니다.\\n\\n또한 대체 에너지원은 에너지 수요에 대한 지속 가능하고 장기적인 해결책을 제공합니다. 화석 연료의 매장량은 유한하며 결국 고갈될 것이지만, 재생 에너지원은 지속적이고 안정적인 전력 공급원을 제공할 수 있습니다. 이는 에너지 공급을 더욱 안전하고 독립적으로 만들 뿐만 아니라 재생 불가능한 자원에 대한 의존도를 줄이는 데도 도움이 됩니다.\\n\\n결론적으로, 대체 에너지원의 도입은 기후 위기를 해결하는 데 매우 중요합니다. 청정 에너지원으로 전환함으로써 온실가스 배출을 줄이고 기후 변화의 부정적인 영향에 대처하며 미래 세대를 위한 지속가능하고 안정적인 에너지 공급을 보장할 수 있습니다.',\n",
              " '레스토랑의 음식은 훌륭하지만 가격은 다소 비쌉니다.',\n",
              " '알리샤의 올 내추럴 잼으로 당신의 욕구를 충족시켜 보세요! 맛있는 맛을 보장하기 위해 최고급 재료로 만든 최신 제품입니다. 한 입 베어 물 때마다 자연스러운 단맛의 완벽함을 경험하세요. #알리샤잼 #자연의맛 #건강한식단.',\n",
              " '다음은 무작위로 생성된 8자 비밀번호입니다: rT8$jLpZ.\\n\\n보안을 위해 고유한 비밀번호를 사용하고 여러 계정에서 공유하거나 재사용하지 않는 것이 좋습니다.',\n",
              " '버블 정렬은 목록에서 인접한 숫자 쌍을 비교하여 순서가 잘못된 경우 서로 바꾸는 방식으로 작동하는 간단한 정렬 알고리즘입니다.\\n\\n정리되지 않은 숫자 목록이 있다고 상상해 보세요. 크기가 다른 공 몇 개가 모두 뒤섞여 있다고 생각해보세요. 목표는 손의 한쪽 끝에서 다른 쪽 끝으로 공의 크기가 커지도록 하는 것입니다. 이를 위해 바로 옆에 있는 두 개의 공을 비교합니다. 오른쪽 공이 왼쪽 공보다 작으면 공을 바꾸면 됩니다. 그런 다음 공 하나를 오른쪽으로 이동하고 두 공(두 번째 공과 세 번째 공)을 비교합니다. 오른쪽 공(세 번째 공)이 왼쪽 공(두 번째 공)보다 작으면 두 공을 바꿉니다. 마지막까지 전체 공 목록에서 이 방법을 계속 반복합니다. 마지막 공에 도착하면 가장 큰 공이 여기에 위치해야 합니다.\\n\\n이제 시작했던 지점으로 돌아가 전체 과정을 다시 수행합니다. 여기서 중요한 점은 이미 가장 큰 공의 위치를 찾았다면 더 이상 그 앞에 있는 공과 비교할 필요가 없다는 것입니다. 즉, 두 번째 스왑 실행에서는 끝까지 갈 필요가 없습니다. 끝내기 전에 공 하나를 멈출 수 있습니다. 이제 두 번째로 큰 공이 정당한 위치에 있습니다.\\n\\n이 과정을 반복하고 더 이상 공을 교환할 필요가 없을 때까지 매번 한 개씩 적은 공을 비교하면서 목록을 반복해서 살펴봅니다. 이 시점에서 모든 공은 한쪽 끝에서 다른 쪽 끝까지 크기 순서대로 완전히 정리됩니다. 이것이 버블 정렬이 작동하는 방식입니다!',\n",
              " '개선은 자동 동사입니다.',\n",
              " '스페인의 수도는 마드리드입니다.',\n",
              " '집을 임대하기로 한 것은 신중한 결정이었습니다.',\n",
              " '보고 싶어요.',\n",
              " '1',\n",
              " 'API는 애플리케이션 프로그래밍 인터페이스의 약자입니다. 서로 다른 소프트웨어 프로그램 또는 시스템 간의 통신을 가능하게 하는 일련의 규칙과 프로토콜입니다. 기본적으로 서로 다른 애플리케이션이 구조화되고 체계적인 방식으로 데이터와 서비스를 서로 공유할 수 있는 방법을 제공합니다. API는 한 소프트웨어가 다른 소프트웨어에 정보나 서비스를 요청하는 방식을 정의하고 요청 형식과 응답 형식을 지정합니다. 이를 통해 개발자는 전체 코드베이스나 내부 작동 방식을 이해하지 않고도 다른 시스템이나 서비스의 기능을 활용할 수 있는 프로그램과 애플리케이션을 구축할 수 있습니다. API를 사용하면 개발자는 자체 프로그램 구축에 집중하는 동시에 다른 시스템의 기능을 활용하여 더욱 풍부한 사용자 경험을 제공할 수 있습니다. 요약하자면, API는 두 개 이상의 개별 소프트웨어 시스템 간의 번역기로 볼 수 있으며, 이를 통해 서로 원활하고 효율적인 방식으로 상호 작용할 수 있습니다.',\n",
              " 'True',\n",
              " '새끼 고양이 - 명사\\n종종 - 부사\\n사기꾼 - 동사\\n주위 - 전치사\\n흥분하다 - 부사.',\n",
              " '1. 식사 계획 세우기 - 한 주 동안의 식사 계획을 세우고 그에 따라 장보기. 이렇게 하면 과잉 구매를 방지하고 불필요한 음식물 쓰레기가 발생할 가능성을 줄일 수 있습니다.\\n\\n2. 남은 음식을 현명하게 사용하세요 - 남은 음식을 창의적으로 사용하여 새로운 식사에 포함하거나 새로운 요리로 용도를 변경하세요.\\n\\n3. 식품을 올바르게 보관하기 - 식품의 유통기한을 늘리기 위해 냉장고나 냉동실에 올바르게 보관하세요.\\n\\n4. 유통기한 이해하기 - \"유통기한\"과 \"사용기한\"은 혼동될 수 있습니다. 불필요하게 음식을 버리지 않도록 시간을 내어 차이점을 알아두세요.\\n\\n5. 남은 음식 기부하기 - 남은 음식을 버리는 대신 지역 푸드뱅크나 쉼터에 기부하는 것을 고려하세요.\\n\\n6. 음식물 쓰레기 퇴비화 - 음식물 찌꺼기를 버리지 말고 퇴비화하세요. 이렇게 하면 쓰레기를 줄이는 동시에 토양을 풍부하게 하는 데 도움이 됩니다.\\n\\n7. 음식물 쓰레기 모니터링 - 버려지는 음식물을 추적하여 그에 따라 구매 및 요리 습관을 조정할 수 있습니다.\\n\\n8. 소량으로 제공 - 음식을 소량으로 제공하여 과식을 방지하고 식사 시 발생하는 음식물 쓰레기의 양을 줄입니다.\\n\\n9. 여분의 식재료 냉동 보관 - 상하기 전에 사용하지 않을 식재료가 남는다면 나중에 사용할 수 있도록 냉동 보관하세요.\\n\\n10. 보존 방법 배우기 - 과일과 채소가 남는 경우 절임이나 통조림으로 보존하는 방법을 배우세요. 이렇게 하면 유통기한을 연장하고 음식물 쓰레기를 줄이는 데 도움이 됩니다.',\n",
              " '이 책의 주제는 인생에서 예기치 않은 사건과 비극에 대응하는 사람들의 이야기를 통해 회복탄력성과 변화에 대한 대처에 관한 것으로 보입니다.',\n",
              " '직사각형의 면적은 길이에 너비를 곱하여 계산할 수 있습니다. 이 경우 직사각형의 길이는 10cm, 너비는 5cm로 주어집니다. 따라서 주어진 치수의 직사각형의 넓이는 `10cm x 5cm = 50cm²`입니다.',\n",
              " '<!DOCTYPE html>\\n<html>\\n  <head>\\n    <meta charset=\"utf-8\" />\\n    <title>로보틱스 - 소개</title>\\n  </head>\\n\\n  <body>\\n    <h1 style=\"text-align: 가운데;\">로보틱스 - 소개</h1>\\n\\n    <p>\\n      로봇 공학은 로봇의 설계, 구성, 작동 및 사용을 다루는 공학 분야입니다. 로봇은 일반적으로 컴퓨터로 프로그래밍할 수 있는 기계로, 신뢰할 수 있고 예측 가능한 방식으로 복잡한 일련의 작업을 수행할 수 있습니다. 로봇 기술은 제조, 운송, 의료, 엔터테인먼트, 우주 탐사 등 다양한 분야에서 사용됩니다.\\n    </p>\\n\\n    <H2>로보틱스의 역사</h2>\\n    <p>\\n      자율적으로 작동할 수 있는 기계를 만든다는 개념은 고대로 거슬러 올라갑니다. 그리스인들이 사용한 최초의 로봇은 \"안티키테라 메커니즘\"이라고 불렀습니다. 16세기에 레오나르도 다빈치가 만든 \"철의 기사\"는 사람처럼 보이는 자동화된 기계로, 앉아서 팔을 흔들고 머리를 움직일 수 있는 실물 크기의 로봇을 만들었습니다. 로봇 개발 분야는 주로 20세기에 시작되었으며 디지털 기술과 컴퓨터의 등장으로 급속도로 성장했습니다.\\n    </p>\\n\\n    <h2>로봇의 종류</h2>\\n    <p>\\n      로봇에는 다양한 목적을 위해 설계된 다양한 유형이 있습니다. 가장 일반적인 로봇 유형으로는 산업용 로봇, 모바일 로봇, 서비스 로봇, 연구용 로봇 등이 있습니다. 산업용 로봇은 제조 환경에서 사용하도록 설계되었으며 일반적으로 용접, 도장, 조립과 같은 작업에 사용됩니다. 모바일 로봇은 주변 환경을 이동할 수 있으며 운송, 감시, 수색 및 구조와 같은 작업에 주로 사용됩니다. 서비스 로봇은 사람과 상호 작용하도록 설계되었으며 일반적으로 청소, 요리, 쇼핑과 같은 작업에 사용됩니다. 연구 로봇은 과학 연구 및 탐사에 사용되며 데이터 수집이나 측정과 같은 특정 작업을 수행하도록 설계되는 경우가 많습니다.\\n    </p>\\n\\n    <H2>로봇과 AI</h2>\\n    <p>\\n      인공 지능(AI)은 일반적으로 인간의 지능이 필요한 지능적인 작업을 수행할 수 있는 소프트웨어 프로그램을 개발하는 데 중점을 두는 컴퓨터 과학 분야입니다. AI 기술은 로봇이 복잡한 작업을 독립적으로 수행할 수 있도록 로봇 공학에서 자주 사용됩니다. 예를 들어, AI 알고리즘은 다음과 같은 작업에 사용될 수 있습니다.',\n",
              " '18~25세의 미국 온라인 쇼핑객은 기술에 능숙하고 이커머스 활동에 자주 참여하는 젊은 성인 고객층을 대표합니다. 이 연령대는 인터넷과 함께 성장하고 기술에 익숙한 디지털 네이티브일 가능성이 높습니다. 이들은 다양한 디지털 플랫폼과 디바이스를 사용하여 온라인에서 제품 및 서비스를 조사, 비교, 구매할 가능성이 높습니다. 이들은 편리함, 다양성, 최적의 상품을 빠르게 찾고 비교할 수 있는 능력 등 온라인 쇼핑에 대한 다양한 동기를 가지고 있을 수 있습니다. 또한 빠른 무료 배송, 간편한 반품, 개인화된 추천에 대한 기대치가 높을 수 있습니다. 이들은 참여도가 높고 장기적인 충성도가 높기 때문에 비즈니스에 매우 중요한 고객 세그먼트입니다.',\n",
              " '\"그것 때문에 잠을 잃지 마세요.\" 이 문구는 어떤 일에 대해 지나치게 걱정하거나 불안해하지 말라는 의미입니다.',\n",
              " '다음은 서반구에 위치한 국가 목록입니다:\\n\\n1. 앤티가 바부다\\n2. 아르헨티나\\n3. 바하마\\n4. 바베이도스\\n5. 벨리즈\\n6. 볼리비아\\n7. 브라질\\n8. 캐나다\\n9. 칠레\\n10. 콜롬비아\\n11. 코스타리카\\n12. 쿠바\\n13. 도미니카\\n14. 도미니카 공화국\\n15. 에콰도르\\n16. 엘살바도르\\n17. 그레나다\\n18. 과테말라\\n19. 가이아나\\n20. 아이티\\n21. 온두라스\\n22. 자메이카\\n23. 멕시코\\n24. 니카라과\\n25. 파나마\\n26. 파라과이\\n27. 페루\\n28. 세인트 키츠 네비스\\n29. 세인트 루시아\\n30. 세인트 빈센트 그레나딘\\n31. 수리남\\n32. 트리니다드 토바고\\n33. 미국\\n34. 우루과이\\n35. 베네수엘라',\n",
              " '다음은 직원 급여를 기록하는 데이터베이스에 대한 제안 디자인입니다:\\n\\n1. **직원 테이블**: 이 테이블에는 직원에 대한 모든 관련 정보가 저장됩니다. 이 테이블의 일부 필드에는 다음이 포함될 수 있습니다:\\n\\n- 직원 ID: 각 직원의 고유 식별자입니다.\\n- 이름: 직원의 이름입니다.\\n- 성: 직원의 성입니다: 직원의 성입니다.\\n- 이메일: 직원의 이메일 주소입니다.\\n- 고용 날짜: 직원이 고용된 날짜입니다.\\n- 부서: 직원이 근무하는 부서입니다.\\n\\n2. **급여 테이블**: 이 테이블에는 직원의 급여에 관한 모든 관련 정보가 저장됩니다. 이 테이블의 일부 필드에는 다음이 포함될 수 있습니다:\\n\\n- 급여 ID: 각 급여 기록에 대한 고유 식별자\\n- 직원 ID: 이 급여 기록의 대상 직원으로, 이 필드는 Employee 테이블을 참조하는 외래 키여야 합니다.\\n- 급여 금액: 직원의 급여 금액입니다.\\n- 시작 날짜: 이 급여 금액이 발효된 날짜입니다.\\n- 종료 날짜: 이 급여 금액이 효력을 잃은 날짜입니다(종료 날짜가 없는 경우 이 급여 금액은 여전히 유효합니다).\\n- 통화: 급여가 지급되는 통화입니다.\\n- 지급 빈도: 급여가 매주, 격주 또는 매월 지급되는지 여부입니다.\\n\\n이 디자인을 사용하면 급여 금액, 통화 및 지급 주기 변경을 포함한 각 직원의 급여 내역을 변경할 때마다 급여 테이블에 새 기록을 추가하여 기록할 수 있습니다. 이렇게 하면 직원의 현재 급여와 급여 이력을 추적할 수 있습니다.',\n",
              " '다음은 스트레스를 줄이는 데 도움이 될 수 있는 팁 목록입니다:\\n\\n1. 이완 기술을 연습하세요: 심호흡, 명상 또는 요가를 통해 마음을 진정시키고 몸의 긴장을 완화하세요.\\n\\n2. 활동적인 생활을 유지합니다: 규칙적인 운동은 스트레스 호르몬을 방출하고 전반적인 웰빙을 개선하는 데 도움이 될 수 있습니다.\\n\\n3. 충분한 수면을 취합니다: 숙면을 취하면 기분이 상쾌해지고 스트레스에 더 잘 대처할 수 있습니다.\\n\\n4. 정리 정돈하기: 정리 정돈을 하면 통제력을 높이고 압도당하는 느낌을 덜 받을 수 있습니다.\\n\\n5. 우선순위를 정하세요: 무엇이 중요한지 파악하고 그 일에 먼저 집중하세요. 모든 일을 한꺼번에 처리하려고 하면 스트레스를 받을 수 있습니다.\\n\\n6. 긍정적인 마음을 유지하세요: 인생의 좋은 일에 집중하고 자신의 성취와 강점을 상기하세요.\\n\\n7. 스트레스 요인에 대한 노출을 제한합니다: 가능하면 부정적인 사람들과 보내는 시간을 제한하거나 스트레스를 유발하는 특정 상황을 피하는 등 생활에서 스트레스 요인의 양을 줄이세요.\\n\\n8. 휴식을 취하세요: 업무나 기타 스트레스가 많은 활동에서 정기적으로 휴식을 취하고 재충전하세요.\\n\\n9. 연결 상태를 유지하세요: 가족과 친구의 사회적 지원은 힘든 시기를 극복하는 데 도움이 될 수 있습니다.\\n\\n10. 도움을 구하세요: 스트레스가 감당하기 어려울 정도라면 상담사나 치료사 등 전문가에게 도움을 요청하세요.',\n",
              " '다음은 새로운 모바일 앱을 홍보하기 위한 몇 가지 마케팅 전략입니다:\\n\\n1. 소셜 미디어 광고 캠페인: Facebook, Instagram, Twitter와 같은 주요 소셜 미디어 플랫폼을 활용하여 많은 잠재 고객에게 도달하고 앱을 홍보하세요.\\n\\n2. 앱 스토어 최적화: 앱 스토어 검색 결과에서 더 높은 순위를 차지할 수 있도록 앱의 제목, 설명, 키워드를 최적화합니다.\\n\\n3. 인플루언서 마케팅: 소셜 미디어 인플루언서 및 블로거와 협력하여 앱을 널리 알리고 가시성을 높일 수 있습니다.\\n\\n4. 콘텐츠 마케팅: 유용하고 유익한 블로그 게시물, 동영상, 인포그래픽을 개발하여 잠재 고객을 유치하고 참여를 유도하세요.\\n\\n5. 이메일 마케팅: 특정 대상에게 앱을 홍보할 수 있는 타겟 이메일 캠페인을 생성합니다.\\n\\n6. 추천 마케팅: 기존 사용자가 보상이나 인센티브를 받고 친구나 가족을 앱에 추천하도록 유도하세요.\\n\\n7. 인앱 광고: 다른 인기 앱 내에서 새 앱을 광고하여 관련성이 높은 많은 잠재 고객에게 도달할 수 있습니다.\\n\\n8. 보도 자료: 보도 자료를 개발하여 관련 미디어 매체에 배포하여 앱에 대한 보도 범위와 관심을 확보하세요.\\n\\n9. 검색 엔진 마케팅: 유료 검색 광고를 활용하여 특정 키워드를 타겟팅하고 앱의 랜딩 페이지로 트래픽을 유도합니다.\\n\\n10. 이벤트 마케팅: 이벤트, 컨퍼런스 또는 웨비나를 주최하거나 참여하여 잠재 고객과 소통하고 앱을 홍보합니다.',\n",
              " '인공지능으로서 저는 디자인이나 로고를 만들 수 있는 기능이 없습니다. 하지만 직접 또는 전문 그래픽 디자이너의 도움을 받아 로고를 만들 수 있는 몇 가지 방법을 소개합니다:\\n\\n1. 색 구성표를 선택합니다: 모바일 애플리케이션의 브랜딩 및 미적 감각에 맞는 색 구성표를 선택합니다. 눈에 편하고 서로 잘 어울리는 색상을 사용하는 것이 좋습니다.\\n\\n2. 아이콘을 추가합니다: 좋은 로고에는 모바일 애플리케이션을 나타내는 간단한 아이콘이 있어야 합니다. 예를 들어 피트니스 관련 앱이라면 달리기하는 사람이나 역기 아이콘을 포함시켜 앱을 나타낼 수 있습니다.\\n\\n3. 올바른 글꼴을 선택합니다: 로고는 명확하고 읽기 쉬워야 하므로 로고 텍스트에 적합한 글꼴을 선택하는 것이 중요합니다. 가독성이 좋고 앱의 스타일에 맞는 글꼴을 찾아야 합니다.\\n\\n4. 단순하게 유지하세요: 단순한 디자인일수록 더 잘 알아볼 수 있고 기억하기 쉽습니다. 로고에 너무 많은 세부 사항이나 너무 많은 요소를 넣지 마세요.\\n\\n5. 다양한 디자인 레이아웃을 실험해 보세요: 아이콘을 텍스트 위나 옆에 배치하는 등 로고 요소의 다양한 배열을 시도하여 앱에 가장 잘 어울리는 것이 무엇인지 확인하세요.\\n\\n6. 피드백 받기: 로고 아이디어를 다른 사람들에게 보여주고 어떤 것이 효과가 있고 개선할 수 있는지에 대한 피드백을 받습니다. 그런 다음 피드백에 따라 변경합니다.\\n\\n7. 디자인 완성하기: 마음에 드는 디자인이 완성되면 최종적으로 모바일 애플리케이션에서 사용할 수 있도록 준비합니다.',\n",
              " '그는 가게에 갔습니다.',\n",
              " '그녀는 걸어서 학교에 갈 것입니다.',\n",
              " '고객님께,\\n\\n먼저, 저희 제품으로 인해 불편을 겪으셨거나 실망하신 점 진심으로 사과드립니다. 저희는 고객이 구매에 완전히 만족하는 것을 중요하게 생각하며, 고객님과 같은 우려 사항을 매우 심각하게 받아들입니다.\\n\\n제품 관련 문제에 대한 자세한 정보를 제공해 주시겠습니까? 그래야 문제를 해결할 수 있는 최선의 해결책을 찾기 위해 함께 노력할 수 있습니다.\\n\\n제가 여러분을 도와드리기 위해 여기 있으며, 여러분을 위해 최선을 다해 문제를 해결해 드릴 테니 안심하시기 바랍니다. 저희는 귀하의 비즈니스를 소중히 여기며 문제를 바로잡을 수 있는 기회를 주셔서 감사합니다.\\n\\n이 문제를 제기해 주셔서 감사합니다.\\n\\n진심으로 감사드립니다,\\nAI 어시스턴트',\n",
              " '불안해합니다.',\n",
              " '그는 입장하자마자 모두를 깨웠습니다.',\n",
              " '소셜 미디어에서 가장 일반적으로 공유되는 콘텐츠 유형은 플랫폼마다 다르지만 일반적으로 다음과 같은 것들이 가장 인기가 있습니다:\\n\\n1. 시각적 콘텐츠: 이미지와 동영상과 같은 시각적 콘텐츠는 소셜 미디어에서 가장 인기 있는 콘텐츠 유형 중 하나입니다. 사람들은 재미있는 밈, 아름다운 사진, 유익한 인포그래픽 등 시선을 사로잡는 매력적인 비주얼 콘텐츠를 공유하는 것을 좋아합니다.\\n\\n2. 사용자 제작 콘텐츠: 사용자 제작 콘텐츠는 리뷰, 사진, 동영상, 블로그 게시물 등 플랫폼의 사용자가 만든 모든 콘텐츠를 말합니다. 이러한 유형의 콘텐츠는 사람들의 공감을 불러일으키고 공감을 얻을 수 있기 때문에 인기가 있습니다.\\n\\n3. 뉴스 및 시사: 소셜 미디어 플랫폼이 뉴스와 정보의 주요 출처가 되면서 사람들은 뉴스 기사, 동영상 및 기타 시사 관련 콘텐츠를 점점 더 많이 공유하고 있습니다.\\n\\n4. 영감과 동기를 부여하는 콘텐츠: 영감을 주는 명언, 이야기, 메시지는 긍정적인 자극을 주고 기분을 좋게 해주기 때문에 소셜 미디어에서 인기가 높습니다.\\n\\n5. 교육 콘텐츠: 튜토리얼, 가이드, 설명과 같은 교육용 콘텐츠도 소셜 미디어에서 인기가 있습니다. 사람들은 새로운 것을 배우기를 좋아하며 소셜 미디어는 유익한 콘텐츠에 액세스하고 공유할 수 있는 좋은 장소입니다.\\n\\n궁극적으로 콘텐츠의 인기는 플랫폼, 대상, 심지어 시기에 따라 다르지만 일반적으로 이러한 콘텐츠 유형은 소셜 미디어에서 가장 일반적으로 공유되는 콘텐츠 유형에 속합니다.',\n",
              " '이 기사에서는 오늘날 사회에서 인터넷의 중요성과 인터넷이 어떻게 커뮤니케이션을 획기적으로 변화시키고 전 세계적으로 빠르고 저렴한 정보 확산을 가능하게 했는지에 대해 설명합니다.',\n",
              " '이 글의 주요 내용은 로봇 산업이 빠르게 성장하고 있으며 로봇 기술이 다양한 산업과 애플리케이션에서 사용되고 있다는 것입니다.',\n",
              " '잘못된 단어는 \"거대한\"이며 더 나은 버전은 \"거대한\"이 될 것입니다.',\n",
              " '해당 문장의 끝에는 마침표를 사용해야 합니다: 새를 살펴봅시다.',\n",
              " '불이 난 집은 이웃을 놀라게 하는 상황을 만들었습니다.',\n",
              " '\"Il est incroyable\"이라는 문장에 사용된 언어는 프랑스어입니다.',\n",
              " '\"미국 재생 에너지의 미래: 종합적인 전망\"',\n",
              " '요한과 마리아의 관계는 남매의 관계입니다. 두 사람은 공통의 부모를 둔 가족적 유대감을 공유합니다.',\n",
              " '아니요, 이 문장은 문법적으로 올바르지 않습니다. 이 문맥에서 대명사 \\'그녀\\'는 여성인 사람을 가리키고 \\'그 소년\\'은 남성인 사람을 가리키므로 올바르지 않습니다. 문장을 문법적으로 올바르게 만들려면 \"그녀\"를 \"그의\"로 변경하여 \"그 소년\"의 성별과 일치시키면 됩니다. 올바른 문장은 다음과 같습니다: \"그 소년은 장난감을 가지고 놀고 있었습니다.\"',\n",
              " '1. 유기농 식사 배달: 현지에서 지속 가능한 방식으로 조달한 건강한 유기농 식사를 고객의 집 앞까지 배달합니다.\\n\\n2. 식단별 배달: 글루텐 프리, 케토 또는 비건 식단과 같은 특정 식단 요구 사항을 충족하는 식사 배달 옵션을 전문적으로 제공하고 각 식사와 함께 영양 정보를 제공합니다.\\n\\n3. 문화 요리 배달: 다양한 문화와 요리의 전통 요리 또는 퓨전 요리를 순환 메뉴로 제공하여 고객이 새로운 맛과 세계 음식을 경험할 수 있도록 지원합니다.\\n\\n4. 밀키트 배달: 고객이 직접 요리할 수 있도록 미리 준비된 재료와 따라 하기 쉬운 레시피가 포함된 밀키트를 매주 구독하여 문 앞까지 배달해 드립니다.\\n\\n5. 농장에서 식탁까지 배달: 현지에서 재배한 신선한 제철 농산물과 제품을 고객의 집 앞까지 직접 배송하여 지역 농가와 소비자를 연결합니다.\\n\\n6. 가족식 식사 배달: 가정에서 조리한 푸짐한 양의 가정식 간편식을 문 앞까지 배달하여 바쁜 가족들이 양질의 가정식 식사를 쉽게 즐길 수 있도록 합니다.\\n\\n7. 건강 중심 배달: 깨끗한 통식품 재료를 사용하여 체중 감량, 근육 증가 또는 전반적인 웰빙 개선과 같은 고객의 목표에 맞춘 맛있고 건강한 식사를 제공합니다.\\n\\n8. 미식가 식사 배달: 고급 레스토랑 수준의 식사를 고객의 집 앞까지 배달하여 집에서 편안하게 고급 식사 경험을 제공합니다.\\n\\n9. 냉동 식품 배달: 셰프가 직접 조리한 고품질의 냉동 식품을 집에서 간편하게 재가열하여 즐길 수 있도록 배송함으로써 바쁜 개인이나 가족에게 편리한 솔루션을 제공합니다.\\n\\n10. 조식 배달: 매일 아침 신선하고 건강하며 맛있는 아침 식사 옵션을 고객의 집 앞까지 직접 배달하여 하루를 활기차게 시작하세요.',\n",
              " '옛날 옛적, 아주 먼 나라에 마법의 활과 화살이 있었어요. 숲의 현명한 엘프들이 고대의 마법과 지식으로 활과 화살을 만들었다는 전설이 전해져 내려오죠. 활은 마법에 걸린 나무 중 가장 튼튼한 나무로 만들었고, 활줄은 최고급 거미줄로 엮었죠. 반면에 화살은 드워프들이 깊은 산속에서 그들의 전문 기술을 사용하여 가벼움과 날카로움의 완벽한 균형을 이루는 화살을 만들었습니다.\\n\\n전설에 따르면 마법의 활과 화살을 휘두르는 자에게는 어떤 적도 물리치고 어떤 장애물도 극복할 수 있는 힘이 주어졌다고 합니다. 하지만 모든 강력한 힘에는 무거운 책임이 따랐죠. 마법의 활과 화살을 함부로 사용하면 끔찍한 결과를 초래할 수 있었기 때문이죠.\\n\\n어느 날 한 젊은 모험가가 산속 깊은 비밀 동굴에 숨겨져 있던 마법의 활과 화살을 우연히 발견했어요. 전설과 그 힘에 대해 들어본 적이 있는 그는 활과 화살을 가지고 여행을 떠나기로 결심했죠.\\n\\n땅을 가로질러 여행하는 동안 그는 많은 도전과 위험에 직면했지만 항상 마법의 활과 화살을 가까이에 두었습니다. 도움이 필요할 때마다 활을 뽑고 화살을 조준하면 그 안에 담긴 마법이 그를 목표를 향해 인도해 주었죠.\\n\\n그래서 이 어린 모험가는 마법의 활과 화살의 도움으로 불가능을 가능하게 만드는 수많은 위대한 모험을 떠났어요. 그는 그 힘을 현명하게 사용했고 이 땅의 가장 위대한 영웅 중 한 명으로 알려지게 되었어요.\\n\\n결국 마법의 활과 화살은 대대로 전해져 대의를 위해 그 힘을 사용할 수 있을 만큼 용감한 사람들을 도왔어요. 그렇게 마법의 활과 화살의 전설은 경이로움과 가능성에 대한 이야기로 계속 이어졌습니다.',\n",
              " '기술이 발전하고 더 안전하고 효율적인 교통수단에 대한 수요가 증가함에 따라 자율 주행 자동차의 인기가 높아지고 있습니다. 자율주행차에 대한 한 가지 아이디어는 첨단 센서와 카메라를 장착하여 안전하고 자율적으로 도로를 탐색할 수 있도록 하는 것입니다. 이 자동차는 머신 러닝 알고리즘을 사용하여 도로 상황, 교통 패턴, 잠재적 위험을 분석하고 이러한 요소에 대응하는 방법에 대해 실시간으로 결정을 내릴 것입니다.\\n\\n이 자동차는 도로의 다른 자율주행 차량과 통신하여 정보를 공유하고 움직임을 조정하여 교통 혼잡을 줄이고 안전을 개선할 수 있습니다. 실시간 교통 정보를 기반으로 속도와 경로를 조정하고 교통 체증이나 사고를 피하기 위해 자동으로 우회할 수 있습니다.\\n\\n또한 자동 긴급 제동, 차선 이탈 경고, 충돌 방지 시스템과 같은 안전 기능이 탑재되어 차량과 탑승자가 항상 도로에서 안전하게 주행할 수 있도록 보장합니다.\\n\\n또한 자율주행차는 사용자 친화적인 인터페이스를 갖추고 있어 승객이 목적지와 선호하는 경로를 입력할 수 있으며, 예상 도착 시간과 지연 가능성에 대한 정보도 제공합니다. 이를 통해 자동차 여행이 더욱 편리하고 스트레스 없이 가능해질 것이며, 사람들은 자동차가 운전을 처리하는 동안 다른 일에 집중할 수 있을 것입니다.',\n",
              " '\"기생충\"은 2019년에 개봉하여 전 세계를 강타한 한국 스릴러 영화입니다. 이 영화는 사회 풍자, 블랙 유머, 강렬한 불편함의 순간이 혼합된 다크 코미디의 모든 요소를 갖춘 세심하게 제작된 걸작입니다.\\n\\n부유한 박씨 집안과 가난한 김씨 집안 두 가족의 이야기를 통해 부자와 가난한 자를 가르는 넓은 격차와 경제적 불평등이 인간 관계를 어떻게 왜곡하고 뒤틀어 놓는지 살펴봅니다. 봉준호 감독은 출연진들의 뛰어난 연기를 이끌어냈고, 두 집안의 각 구성원은 복잡하고 인간적인 모습으로 훌륭하게 묘사되었습니다.\\n\\n이 영화의 가장 강력한 측면 중 하나는 세트, 조명 및 구도를 잘 활용하여 주제를 전달하는 시각적 스토리텔링입니다. 줄거리는 한 반전에서 다른 반전으로 능숙하게 움직이며 관객을 좌석의 가장자리에 앉게 하고 영화의 결론은 충격적이면서도 피할 수 없는 것입니다.\\n\\n전반적으로 \\'기생충\\'은 독특하고 잊을 수 없는 방식으로 현대 사회를 탐구하는 매력적이고 강력한 영화입니다. 생각을 자극하고 재미있는 영화 경험을 원하는 모든 분께 강력히 추천합니다.',\n",
              " \"주어진 문장의 접속사는 'and'입니다. 접속사는 두 개 이상의 단어, 구 또는 절을 결합하는 단어로, '그리고'는 문법 유형이 비슷한 두 개 이상의 구, 절 또는 단어를 결합하는 데 사용되는 가장 일반적인 접속사 중 하나입니다.\",\n",
              " '선형 회귀는 독립 변수(X)와 종속 변수(Y) 사이의 관계를 찾는 방법입니다. 피자의 크기를 기준으로 피자를 만드는 데 걸리는 시간을 예측하려고 한다고 가정해 보겠습니다. 피자의 크기는 X이고 피자를 만드는 데 필요한 시간은 Y입니다.\\n\\n선형 회귀에서는 X와 Y의 관계를 나타내는 가장 잘 맞는 선을 찾으려고 합니다. 즉, 모든 데이터 포인트에 최대한 근접하는 선을 찾으려고 합니다.\\n\\n따라서 피자의 예에서는 다양한 크기의 피자와 피자를 만드는 데 걸리는 시간에 대한 데이터를 수집합니다. 그런 다음 선형 회귀를 사용하여 피자의 크기가 피자를 만드는 데 필요한 시간에 어떤 영향을 미치는지 보여주는 최적의 선을 찾습니다. 이 선이 나오면 이를 사용하여 어떤 크기의 피자를 만드는 데 걸리는 시간을 예측할 수 있습니다.\\n\\n선형 회귀는 일반적으로 예측과 예측을 하는 데 사용되며, 여러 변수 간의 관계를 이해하는 데 강력한 도구입니다.',\n",
              " '\"고양이와 개에게 비가 내린다\"는 관용구는 마치 하늘에서 동물이 떨어지는 것처럼 매우 많은 비가 내리거나 쏟아지는 것을 의미합니다. 격렬한 폭풍우를 묘사하는 데 사용되는 다채로운 표현입니다.',\n",
              " '다음 단락에서는 메리가 살고 있는 작은 마을에서 평범하지 않거나 예상치 못한 사건이 발생하여 수년 동안 거주해온 그녀에게 놀라움이나 놀라움을 유발할 수 있습니다.',\n",
              " '온도는 섭씨 34.444444444444도입니다.',\n",
              " '미국 경제는 1989년과 2019년 사이에 두 배 이상 성장했습니다. 지난 20년보다 빠른 이러한 성장은 정보 기술의 확장, 근로자 생산성 향상, 소비자 수요, 정부의 연구 개발 투자 등의 요인에 힘입은 결과입니다.',\n",
              " '1. 먹기\\n2. 음주\\n3. 달리기\\n4. 웃기\\n5. 노래 부르기\\n6. 춤추기\\n7. 잠자기\\n8. 요리\\n9. 독서\\n10. 쓰기\\n11. 연주하기\\n12. 수영\\n13. 걷기\\n14. 말하기\\n15. 듣기\\n16. Watching\\n17. 공부하기\\n18. 일하기\\n19. 운동\\n20. 미소 짓기.',\n",
              " '\"팬데믹은 도전 과제이며 즉각적이고 단호한 조치가 필요합니다.\"',\n",
              " \"다음은 'Tenacious'라는 단어의 동의어입니다:\\n\\n1. Persistent\\n2. 결정된\\n3. 단호함\\n4. Steadfast\\n5. Obstinate\\n6. 인내심\\n7. 불굴의\\n8. 흔들리지 않는\\n9. 강한 의지\\n10. 끈질긴.\",\n",
              " '이 게임은 매우 매력적이고 즐겁습니다.',\n",
              " '캘리포니아주 로스앤젤레스에서 훌륭한 레스토랑 경험을 원하신다면 베스티아를 추천해드리고 싶어요. 이 이탈리안 레스토랑은 창의적이고 다양한 지역의 소박한 요리 메뉴를 제공합니다. 맛있는 음식, 멋진 분위기, 훌륭한 서비스로 꾸준히 높은 평가를 받고 있습니다.',\n",
              " '겨울에는 일반적으로 추위와 눈이 내립니다.',\n",
              " '삼각형의 넓이에 대한 공식인 (밑변 x 높이)/2를 사용하여 주어진 입력 값으로 넓이를 계산할 수 있습니다.\\n\\n삼각형의 밑변은 5cm, 높이는 6cm입니다.\\n\\n따라서 삼각형의 넓이는 (5cm x 6cm) / 2 = 15cm²가 됩니다.\\n\\n따라서 삼각형의 넓이는 15cm²입니다.',\n",
              " '\"세상에서 가장 멋진 친구의 생일을 축하합니다! 이 특별한 날에 소원하는 모든 것이 이루어지고, 마음이 기쁨과 웃음으로 가득 차고, 세상이 제공하는 모든 사랑과 행복이 오늘과 항상 여러분을 둘러싸길 바랍니다. 함께 더 많은 잊지 못할 추억을 만들고, 모험과 성장, 무한한 가능성의 또 다른 한 해를 위해 건배!\"',\n",
              " '숫자 2, 5, 10의 평균은 (2 + 5 + 10) / 3 = 17 / 3 = 5.67입니다.',\n",
              " '주어진 이차 방정식은 3x² + 7x - 4 = 0입니다.\\n\\n이 방정식은 이차 공식을 사용하여 풀 수 있습니다: x = (-b ± sqrt(b² - 4ac)) / 2a.\\n\\n여기서 a = 3, b = 7, c = -4입니다.\\n\\n이 값을 이차 공식에 대입하면 다음과 같습니다:\\nx = [ -7 ± sqrt(7² - 4 * 3 * -4)] / (2 * 3)\\n  = [ -7 ± sqrt(73)] / 6\\n\\n따라서 이차 방정식의 해는 다음과 같습니다: x = (-7 + sqrt(73)) / 6 및 x = (-7 - sqrt(73)) / 6입니다.',\n",
              " '그는 그녀에게 점심을 같이 먹자고 할 것입니다. (미래 시제)',\n",
              " '저는 항상 사용자를 지원하고 있습니다.',\n",
              " '잘못된 데이터입니다. 분류를 위해 명확하고 구조화된 형식의 데이터를 제공해 주세요.',\n",
              " '가장 널리 알려진 기록 중 하나에 따르면, 단어 수 측면에서 가장 긴 소설은 프랑스 작가 마르셀 프루스트의 \"과거의 기억\"(잃어버린 시간을 찾아서라고도 함)입니다. 이 소설은 약 120만 단어로 추정됩니다.',\n",
              " '죄송합니다, 인공지능 언어 모델이라 이미지나 첨부 파일을 기반으로 응답을 생성할 수 없습니다. 설명을 생성할 수 있도록 그림에 대해 설명하거나 제목을 입력해 주시겠어요?',\n",
              " '고양이들이 술을 마시고 있습니다.',\n",
              " '파티에 늦었습니다.',\n",
              " '1. 당일 날씨는 어땠나요?\\n2. 그 날을 어떻게 설명하시겠어요?\\n3. 그날은 즐거웠나요 아니면 우울했나요?\\n4. 협조적이고 야외 활동에 도움이 되는 날이었나요?\\n5. 그날을 가장 잘 묘사하는 문장은 무엇인가요?',\n",
              " '분쟁이 격화되면서 지역 주민들 사이에 대규모 난민이 발생하고 있습니다.',\n",
              " '1. Ohio .\\n2. 인디애나\\n3. 미시간\\n4. 일리노이\\n5. 위스콘신',\n",
              " '\"그녀는 책을 썼다\"라는 문장의 직접 목적어는 명사 \"책\"입니다. 직접 목적어는 동작의 수신자이며, 이 경우 \"책\"은 주어 \"그녀\"가 쓴 것입니다.',\n",
              " '지난 회원 회의에서 제안된 클럽을 개선하기 위한 5가지 아이디어를 소개합니다:\\n\\n1. 참여도를 높이세요: 회원들의 관심사에 맞는 활동과 이벤트를 통해 회원들의 참여와 관심을 유도하세요.\\n\\n2. 포용성 증진: 배경이나 경험 수준에 관계없이 모든 회원을 더욱 환영하고 포용하는 환경을 조성하기 위해 노력하세요.\\n\\n3. 교육 기회를 제공합니다: 워크샵, 강의 또는 세미나를 제공하여 멤버가 새로운 기술을 배우고 개인 및 전문성 개발을 통해 성장할 수 있도록 지원합니다.\\n\\n4. 봉사활동을 확대하세요: 지역 단체 또는 기업과 파트너십을 맺거나, 공개 행사를 주최하거나, 소셜 미디어를 사용하여 인지도를 높여 커뮤니티 내에서 클럽의 가시성과 도달 범위를 확대하세요.\\n\\n5. 커뮤니케이션 개선: 정기 뉴스레터, 온라인 포럼 또는 그룹 채팅을 통해 회원 간의 커뮤니케이션을 강화하여 클럽의 최신 소식을 모두에게 알리고 협업을 강화하세요.',\n",
              " '죄송합니다만, 시험을 성공적으로 완료하기 위한 커트라인 점수를 결정할 수 있는 정보가 충분하지 않습니다. 커트라인 점수는 문제의 난이도, 채점 기준, 시험관 또는 기관에서 설정한 합격률 등의 요인에 따라 달라집니다. 커트라인 점수를 확인할 수 있도록 자세한 정보나 사양을 제공해 주실 수 있나요?',\n",
              " '배열의 첫 번째 반복 요소는 6입니다.',\n",
              " '경제학은 개인, 기업, 정부 및 기타 조직이 무한한 욕구를 충족하기 위해 한정된 자원을 사용하는 방법과 이러한 선택으로 인해 발생하는 결과를 연구하는 사회과학입니다. 경제학은 상품과 서비스의 생산, 유통, 소비를 기술, 분석, 설명하는 것을 목표로 합니다.',\n",
              " '연구진에 의해 철저한 조사가 이루어졌습니다.',\n",
              " '예, s2는 s1의 회전입니다.\\n\\n이를 확인하는 한 가지 방법은 s1을 자체와 연결하고 s2가 연결된 문자열의 하위 문자열인지 확인하는 것입니다. 이 방법은 문자열이 회전해도 문자열의 위치만 다를 뿐 문자는 여전히 동일한 순서에 있기 때문에 작동합니다. s1을 그 자체와 연결하면 가능한 모든 회전이 새 문자열에 존재한다는 것을 알 수 있습니다.\\n\\n이 경우, s1을 자체와 연결하면 \"waterbottlewaterbottle\"이 됩니다. \"erbottlewat\"은 실제로 \"waterbottlewaterbottle\"의 부분 문자열이므로 s2는 s1의 회전입니다.',\n",
              " '주어진 배열에서 양수 정수를 추출하려면 람다 함수에 제공된 조건에 따라 True로 평가되는 값을 반환하는 filter() 함수를 사용할 수 있습니다.\\n\\n다음은 Python 코드 스니펫입니다:\\n\\n```\\narr = [5,-2,8,-7,3,-1,0,5]\\n\\nresult = list(filter(lambda x: x > 0, arr))\\n\\nprint(result)\\n```\\n\\nOutput: [5, 8, 3, 5]\\n\\n필터 함수는 배열의 각 요소를 반복하고 해당 요소가 0보다 큰지, 즉 양의 정수인지 확인합니다. 참이면 해당 요소가 결과 목록에 포함됩니다. 그런 다음 양수만 포함된 결과 목록을 표시합니다.',\n",
              " '파이썬에서 주어진 숫자의 계승을 계산하는 함수를 작성하는 한 가지 방법이 있습니다:\\n\\n```python\\ndef factorial(n):\\n    # 기본 사례\\n    if n <= 1:\\n        반환 1\\n    # 재귀적 케이스\\n    else:\\n        반환 n * 계승(n-1)\\n\\n# 예시: 5의 계승 계산\\nnum = 5\\nprint(f\"{num}의 계승은 {factorial(num)}입니다.\")\\n```\\n\\n이 함수는 재귀를 사용하므로 기본 케이스(n <= 1)에 도달할 때까지 스스로 호출합니다. 기본 케이스에 도달하면 함수는 1을 반환합니다. 그렇지 않으면 함수는 기본 케이스에 도달할 때까지 호출할 때마다 n에 (n-1)의 계승을 곱하여 계속 자신을 호출합니다.',\n",
              " '물론 여기 주어진 문자열을 대문자로 변환할 수 있는 Python 함수가 있습니다.\\n\\n```python\\ndef to_uppercase(string:str):\\n    RETURN STRING.UPPER()\\n```\\n\\n예를 들어, 문자열 `Hello, I am your AI Assistant`를 대문자로 변환하려면 다음과 같이 호출하면 됩니다:\\n```python\\nprint(to_대문자(\\'안녕하세요, 저는 당신의 AI 어시스턴트입니다\\'))\\n```\\n출력합니다:\\n```\\n\"안녕하세요, 저는 당신의 AI 어시스턴트입니다\\n```\\n\\n이 함수는 대문자로 변환하려는 문자열인 `string` 매개변수 하나를 받습니다. 함수 내부에서는 모든 문자열 객체에서 사용할 수 있는 `.upper()` 메서드를 사용하여 문자열을 대문자로 변환합니다. 그런 다음 결과 대문자 문자열이 함수에 의해 반환됩니다.',\n",
              " '주어진 배열의 가장 긴 증가 수열은 [7, 8, 9, 11]입니다. 길이는 4입니다.\\n\\n이를 계산하려면 동적 프로그래밍을 사용하여 각 위치에서 끝나는 가장 긴 증가 수열의 길이를 찾은 다음 최대값을 구할 수 있습니다. 다음은 파이썬에서 계산하는 방법의 예입니다:\\n\\n```python\\narr = [7, 10, 8, 11, 9, 5]\\nn = len(arr)\\nlis = [1]*n\\n \\nfor i in range(1, n):\\n    for j in range(i):\\n        arr[i] > arr[j] 및 lis[i]< lis[j] + 1:\\n            lis[i] = lis[j]+1\\n \\nprint(max(lis))\\n```',\n",
              " '당사에서 받은 제품 또는 서비스에 대해 1~10점 척도 중 어느 정도 만족하셨습니까?',\n",
              " '물론입니다! 초기 예치금이 $100이고 이자율이 연 복리 6%인 은행 계좌의 금액을 계산하려면 복리 이자 공식인 A = P(1 + r/n)^(nt)를 사용하면 됩니다. 이 경우 A는 계좌의 미래 가치, P는 초기 예치금, r은 연간 이자율, n은 이자가 연간 복리되는 횟수, t는 연도 수입니다.\\n\\n연수를 지정하지 않았으므로 1년을 의미한다고 가정해 보겠습니다. 이자가 매년 복리되는 경우 n = 1이 됩니다.\\n\\n주어진 값을 공식에 대입하면 다음과 같습니다:\\n\\nA = 100(1 + 0.06/1)^(1*1)\\nA = 100(1 + 0.06)^1\\nA = 100(1.06)^1\\nA = 106\\n\\n따라서 1년 후 은행 계좌의 잔액은 $106이 됩니다.',\n",
              " '뉴욕타임스의 이 기사에서는 LG와 ZTE와 같은 신생 기업이 소비자들에게 점점 더 인기를 얻고 있는 저가형 모델을 출시하면서 글로벌 스마트폰 시장의 경쟁이 치열해지고 있다고 설명합니다. Apple과 삼성과 같은 대기업이 여전히 시장을 지배하고 있지만, 이러한 소규모 기업들은 특히 중국과 인도와 같은 신흥 시장에서 시장 점유율을 높이기 위해 공격적인 가격 전략을 사용하고 있습니다. 이러한 경쟁은 기업의 수익률 유지를 더욱 어렵게 만들고 있지만, 혁신을 촉진하고 더 많은 소비자들이 스마트폰을 더 쉽게 이용할 수 있게 하는 원동력이기도 합니다.',\n",
              " '주어진 배열은 여러 날의 주식 가격을 나타내며, 얻을 수 있는 최대 수익을 계산하기 위해 주가가 상승할 때마다 주식을 매수하고 매도하는 접근 방식을 따를 수 있습니다. 즉, 현지 최소값에 주식을 매수하고 현지 최대값에 매도하는 것입니다.\\n\\n다음은 주어진 거래 시퀀스에서 얻을 수 있는 최대 수익의 계산입니다:\\n\\n1. 1일차 매수(arr[0] = 100) 및 4일차 매도(arr[3] = 310), 이익 = 310-100 = 210.\\n\\n2. 5일째 매수 (arr[4] = 40) 및 7일째 매도 (arr[6] = 695), Profit = 695-40 = 655.\\n\\n전체 수익 = 210 + 655 = 865.\\n\\n따라서 주어진 거래 시퀀스에서 얻을 수 있는 최대 수익은 865입니다.',\n",
              " '주어진 숫자 `x`의 제곱근을 계산하려면 Python 라이브러리에서 제공되는 math.sqrt() 메서드를 사용하거나 지수 연산자 `**`를 사용할 수 있습니다.\\n\\n예시:\\n\\n- math` 패키지 내에서 `math.sqrt()` 메서드 사용하기\\n\\n```python\\n임포트 수학\\nmath.sqrt(x)\\n```\\n  \\n- 지수 연산자 `**` 사용\\n\\n```python\\nx ** 0.5\\n```\\n\\n이 두 메서드는 모두 주어진 숫자 `x`의 제곱근을 반환합니다.',\n",
              " '총리는 최근 예산안에서 중소기업 직원을 지원하기 위한 새로운 고용 수당 도입을 발표했습니다.',\n",
              " '갓 블렌딩한 과일 스무디를 만나보세요!🍓🍌🍌🍓\\n\\n맛있게 잘 익은 과일을 블렌딩한 스무디로 갈증을 해소하고 몸에 영양을 공급하세요. 각 컵에는 필수 비타민, 미네랄, 식이섬유가 풍부하게 함유되어 있어 최상의 컨디션을 유지할 수 있습니다.\\n\\n이동 중 아침 식사, 한낮의 에너지 충전 또는 운동 후 간식으로 완벽합니다. 상쾌하고 포만감을 주는 과일 스무디는 여러분이 찾던 건강한 선택입니다. 놓치지 마시고 오늘 한 번 맛보세요! 생과일 #스무디 #건강 #맛있는 #상쾌한 #상큼한',\n",
              " '장엄하고, 강력하고, 사납고, 당당하고, 지배적입니다.',\n",
              " '누군가 150권의 책을 판매했습니다.',\n",
              " '명령의 올바른 순서는 다음과 같습니다:\\n1. 준비\\n2. Pack\\n3. 여행',\n",
              " '웹 서비스는 네트워크를 통해 컴퓨터 간의 상호 운용 가능한 상호 작용을 지원하도록 설계된 소프트웨어 시스템입니다. 웹 서비스 프레임워크라고 하는 공통의 규칙과 프로토콜을 통해 컴퓨터가 서로 통신하고 데이터를 교환할 수 있습니다. 프레임워크는 기본적으로 컴퓨터가 서로 통신하고 함께 작업할 수 있도록 하는 표준과 기술의 조합입니다.\\n\\n웹 서비스 프레임워크의 핵심은 네 가지 핵심 기술입니다: XML(확장 가능한 마크업 언어), SOAP(간단한 객체 액세스 프로토콜), WSDL(웹 서비스 설명 언어), UDDI(범용 설명, 검색 및 통합)입니다.\\n\\nXML은 컴퓨터 간에 교환할 수 있는 형식으로 데이터를 인코딩하는 데 사용되는 마크업 언어입니다. 유연하고 널리 채택된 기술이기 때문에 웹 서비스에 널리 사용됩니다. 웹 서비스 간에 데이터를 정의하고 교환하기 위한 공통 구문을 제공합니다.\\n\\nSOAP는 데이터를 전송하고 웹 서비스 메서드를 호출하는 데 사용되는 메시징 프로토콜입니다. 웹 서비스 간에 정보를 교환하는 수단을 제공하며, 메시지의 형식과 구조를 정의하는 역할을 담당합니다. SOAP 메시지는 일반적으로 HTTP를 통해 전송되지만 다른 전송 프로토콜을 통해서도 전송될 수 있습니다.\\n\\nWSDL은 웹 서비스의 기능을 설명하는 데 사용되는 XML 기반 언어입니다. 기계가 읽을 수 있는 서비스 문서를 제공하고 서비스가 제공할 수 있는 메서드와 데이터 유형을 지정합니다. 클라이언트는 WSDL을 통해 서비스의 기능을 검색하고 서비스와 상호 작용할 수 있는 코드를 생성할 수 있습니다.\\n\\nUDDI는 기업이 웹 서비스를 나열하고 검색할 수 있는 플랫폼 독립적인 XML 기반 레지스트리입니다. 클라이언트가 필요한 서비스를 찾고 상호 작용하는 데 필요한 정보를 얻을 수 있는 서비스 디렉터리를 제공합니다.\\n\\n요약하자면, 웹 서비스 프레임워크는 기계가 표준화된 방식으로 서로 통신하고 데이터를 교환할 수 있도록 하는 기술의 조합입니다. 이 프레임워크는 개방형 표준을 기반으로 하며 널리 채택되고 있으므로 조직에서 웹 서비스를 쉽게 통합하고 운영에서 사용할 수 있습니다.',\n",
              " \"이진 검색 트리(BST)는 각 노드가 다음과 같은 값을 갖는 이진 트리입니다:\\n\\n- 노드의 왼쪽 하위 트리에 저장된 값은 노드의 값보다 작아야 합니다.\\n- 노드의 오른쪽 하위 트리에 저장된 값은 노드의 값보다 크거나 같아야 합니다.\\n- 왼쪽 및 오른쪽 하위 트리는 모두 이진 검색 트리여야 합니다.\\n\\n이진 트리가 이진 검색 트리인지 확인하려면 트리의 순차열 탐색을 수행하고 값을 목록에 저장하면 됩니다. BST를 순서대로 순회하면 정렬된 순서대로 값이 생성됩니다. 따라서 목록이 오름차순으로 정렬된 경우 이진 트리는 BST입니다. 그렇지 않으면 그렇지 않습니다.\\n\\n파이썬에서 위의 접근 방식을 구현하는 방법은 다음과 같습니다:\\n\\n```python\\ndef isBST(tree):\\n    def in_order_traverse(tree, values):\\n        tree가 None이 아닌 경우\\n            in_order_traverse(tree.left, values)\\n            values.append(tree.val)\\n            in_order_traverse(tree.right, values)\\n\\n    values = []\\n    in_order_traverse(tree, values)\\n    return all(values[i] <= values[i + 1] for i in range(len(values) - 1))\\n```\\n\\n또 다른 접근 방식은 왼쪽과 오른쪽 자식이 있는 각 노드를 재귀적으로 확인하는 것입니다. 이렇게 하면 값을 목록에 저장할 필요가 없습니다. 파이썬에서 이를 구현하는 방법은 다음과 같습니다:\\n\\n```python\\ndef isBST(tree):\\n    def is_bst_helper(tree, min_value=float('-inf'), max_value=float('inf')):\\n        if tree가 None:\\n            반환 True\\n        min_value <= tree.val <= max_value가 아니라면:\\n            return False\\n        반환 is_bst_helper(tree.left, min_value, tree.val) 및 is_bst_helper(tree.right, tree.val, max_value)\\n\\n    반환 is_bst_helper(tree)\\n```\",\n",
              " '수중 생물은 매혹적입니다.',\n",
              " '가족 사진 촬영을 위한 좋은 아이디어는 각 가족 구성원의 개성과 관심사를 보여주는 테마 촬영일 수 있습니다. 예를 들어, 가족이 야외 활동을 좋아한다면 모두가 좋아하는 아웃도어 장비를 입고 공원, 숲, 해변에서 촬영하는 것을 고려해 보세요. 가족이 음악이나 미술을 좋아한다면 악기나 미술 용품을 사진에 포함시키는 것도 좋습니다. 또 다른 아이디어는 조부모 및 기타 대가족과 함께 세대별 촬영을 진행하여 세대 간의 사랑과 유대감을 포착하는 것입니다. 빈티지나 복고풍을 테마로 하거나 좋아하는 영화나 책의 캐릭터로 분장하는 등 의상과 소품으로 재미를 더할 수도 있습니다. 핵심은 재미있게 촬영하고 가족 고유의 역동성과 관심사가 사진에서 빛날 수 있도록 하는 것입니다.',\n",
              " \"해시 맵을 사용하여 반복되는 요소 배열에서 반복되지 않는 요소 두 개를 찾을 수 있습니다. 다음은 이를 위해 Python으로 작성된 예제 코드입니다:\\n\\narr = [2, 3, 7, 9, 11, 2, 3, 11]\\n\\n# 빈 해시 테이블 생성\\nhashTable = {}\\n\\n# 배열을 반복하기\\n배열을 반복합니다:\\n    # 해당 요소가 해시 테이블에 있는지 여부 확인\\n    해시 테이블에 있으면\\n        # 존재하면 값을 1씩 증가시킵니다.\\n        hashTable[i] = hashTable[i] + 1\\n    else:\\n        # 존재하지 않으면 해시 테이블의 요소를 1의 값으로 추가합니다.\\n        hashTable[i] = 1\\n\\n# 결과를 저장할 빈 목록을 생성합니다.\\nresult = []\\n\\n# 해시 테이블 반복하기\\n해시 테이블을 반복합니다:\\n    # 요소의 값이 1인지 아닌지 확인합니다.\\n    hashTable[i] == 1:\\n        # 만약 그렇다면, 결과에 추가합니다.\\n        result.append(i)\\n\\nprint(f'반복되지 않는 두 요소는: {result}')\\n\\n###출력:\\n#반복되지 않는 두 요소는 다음과 같습니다: [7, 9]\",\n",
              " \"링크된 목록을 반전시키려면 목록에 있는 각 노드의 '다음' 포인터 방향을 변경해야 합니다. 이 작업은 반복적으로 또는 재귀적으로 수행할 수 있습니다. 다음은 반복적으로 수행하는 방법의 예입니다:\\n\\n1. 이전`, `다음`, `다음` 포인터 세 개를 초기화합니다.\\n2. '이전'을 '없음'으로, '다음'을 목록의 맨 앞에 설정하고 '다음'을 '없음'으로 설정합니다.\\n3. curr`가 `None`이 될 때까지 목록을 반복합니다:\\n    a. `next`를 `curr.next`로 설정합니다.\\n    b. `curr.next`를 `prev`로 설정합니다.\\n    c. `prev`를 `curr`로 설정합니다.\\n    d. `curr`를 `next`로 설정합니다.\\n4. 목록의 헤드를 `prev`로 설정합니다.\\n\\n아래는 이 알고리즘을 구현하는 파이썬 코드 샘플입니다:\\n\\n```python\\ndef reverseList(self, head: Optional[ListNode]) -> Optional[ListNode]:\\n    prev, curr, next = None, head, None\\n    \\n    while curr:\\n        next = curr.next\\n        curr.next = prev\\n        prev = curr\\n        curr = next\\n    \\n    반환 prev\\n```\\n\\n이 코드에서는 먼저 세 개의 포인터를 초기화합니다. 그런 다음 `while` 루프를 사용해 목록을 반복하고 각 단계에서 포인터를 업데이트합니다. curr`가 `None`이 될 때까지 계속하여 목록의 끝에 도달했음을 나타냅니다. 마지막으로 목록의 헤드를 `curr`의 마지막 `None`이 아닌 값인 `prev`로 설정합니다. 이것이 반전된 목록의 새로운 헤드입니다.\",\n",
              " '1. 사자\\n2. 코끼리\\n3. 팬더\\n4. 기린\\n5. 돌고래\\n6. 캥거루\\n7. 호랑이\\n8. 고릴라\\n9. 낙타\\n10. 얼룩말',\n",
              " '물론 카테고리에 따라 이미지를 정렬하는 웹 기반 애플리케이션을 개발하는 방법에 대한 몇 가지 지침을 제공할 수 있습니다. 다음은 따를 수 있는 단계입니다:\\n\\n1. 카테고리 정의하기: 이 웹 기반 애플리케이션을 만드는 첫 번째 단계는 이미지 카테고리를 정의하는 것입니다. 동물, 자연, 음식, 여행, 사람 등과 같이 이미지를 정렬할 수 있는 모든 가능한 이미지 카테고리의 목록을 만들 수 있습니다.\\n\\n2. 개발 환경을 설정합니다: 웹 앱을 개발하려면 컴퓨터에 개발 환경을 설정해야 합니다. 코드 편집기, 로컬 서버, 웹 브라우저가 필요합니다. XAMPP 또는 WAMP와 같은 소프트웨어를 사용하여 로컬 서버를 설정하고 Sublime Text 또는 Visual Studio Code와 같은 원하는 코드 편집기를 사용할 수 있습니다.\\n\\n3. 사용자 인터페이스 만들기: 사용자가 이미지를 업로드할 수 있는 HTML 페이지를 만드는 등 애플리케이션의 프론트엔드 구축을 시작할 수 있습니다. 이미지의 각 카테고리를 표시하기 위해 다른 섹션을 만들 수도 있습니다.\\n\\n4. 이미지 정렬 기능을 구현합니다: 이미지 정렬 기능을 구동하는 백엔드 코드를 작성해야 합니다. JavaScript 또는 Python과 같은 프로그래밍 언어를 사용하고 머신 러닝 알고리즘을 구현하여 이미지를 인식하고 해당 카테고리로 정렬할 수 있습니다. 알고리즘은 이미지 픽셀, 색상 및 이미지 메타데이터를 사용하여 이미지를 분류할 수 있습니다.\\n\\n5. 프론트 엔드와 백엔드를 통합합니다: 사용자 인터페이스를 개발하고 이미지 정렬을 구현한 후에는 프론트엔드와 백엔드 코드를 연결하여 이 둘을 통합해야 합니다.\\n\\n6. 테스트 및 배포: 웹 애플리케이션을 철저히 테스트하여 이미지를 카테고리에 맞게 올바르게 정렬하는지 확인합니다. 앱의 성능에 만족하면 웹 서버에 배포하여 사용자가 액세스할 수 있도록 할 수 있습니다.\\n\\n이 단계를 통해 카테고리에 따라 이미지를 정렬하는 웹 기반 애플리케이션을 개발할 수 있습니다.',\n",
              " '\"나를 찾아서: 어린 소녀의 자아 발견 여정\"',\n",
              " \"이것은 시입니다. 에드거 앨런 포의 시 '까마귀'의 첫 줄입니다.\",\n",
              " '1960년대 - 미국의 컴퓨터 과학자들 사이에서 광역 컴퓨터 네트워킹이라는 개념이 등장했습니다.\\n\\n1969년 - 미국 고등연구계획국(ARPA)에서 최초의 운영 데이터 네트워크인 ARPANET을 출범시켰습니다.\\n\\n1971년 - 레이 톰린슨이 한 컴퓨터에서 다른 컴퓨터로 메시지를 보낼 수 있는 이메일을 발명했습니다.\\n\\n1972년 - 빈트 서프와 로버트 칸이 인터넷의 핵심이 되는 기본 통신 프로토콜인 TCP(전송 제어 프로토콜)와 IP(인터넷 프로토콜)를 설계했습니다.\\n\\n1974년 - 데이터 전송의 기본 기술로 패킷 스위칭의 개념을 확립한 인터넷 창설 제안서가 발표되었습니다.\\n\\n1983년 - 증가하는 군사용 및 민간용 애플리케이션을 수용하기 위해 ARPANET이 MILNET과 새로운 ARPANET의 두 네트워크로 분리되었습니다.\\n\\n1989년 - 팀 버너스 리가 과학자들이 인터넷을 통해 정보를 쉽게 공유할 수 있도록 설계된 시스템인 월드와이드웹을 제안했습니다.\\n\\n1990년 - ARPANET이 폐기되고 월드와이드웹이 출범했습니다.\\n\\n1991년 - 최초의 웹사이트인 info.cern.ch가 온라인에 개설되었습니다.\\n\\n1993년 - 모자이크 웹 브라우저의 출시로 훨씬 더 많은 사람들이 웹에 액세스할 수 있게 되었습니다.\\n\\n1994년 - Amazon과 eBay의 설립으로 전자상거래가 탄생했습니다.\\n\\n1995년 - 닷컴 붐이 시작되고 인터넷 스타트업이 막대한 투자를 받았습니다.\\n\\n2000년 - 닷컴 거품이 꺼졌지만 초고속 광대역 인터넷 시대가 열렸습니다.\\n\\n2004년 - Facebook의 출시와 함께 소셜 네트워킹의 부상이 시작되었습니다.\\n\\n2005년 - YouTube가 출시되어 온라인 동영상 공유의 시대가 열렸습니다.\\n\\n2007년 - iPhone이 출시되어 모바일 인터넷 액세스의 분수령이 되었습니다.\\n\\n2010년 - 구글 드라이브와 드롭박스 같은 서비스가 등장하면서 클라우드 컴퓨팅 개념이 주류가 되었습니다.\\n\\n오늘날 인터넷은 계속해서 진화하고 확장되어 우리 생활, 커뮤니케이션, 비즈니스에서 더욱 필수적인 부분이 되었습니다.',\n",
              " '직책: 데이터 분석 컨설턴트\\n\\n직무 요약:\\n현재 성장하는 팀에 합류할 역동적이고 경험이 풍부한 데이터 분석 컨설턴트를 찾고 있습니다. 이 직책은 고급 분석 기법과 비즈니스 인텔리전스 도구를 활용하여 고객에게 데이터 기반 인사이트를 제공하는 데 핵심적인 역할을 담당하게 됩니다. 성공적인 지원자는 강력한 분석적 배경을 갖추고 복잡한 데이터 분석을 비전문가인 청중에게 명확하고 간결하게 전달할 수 있어야 합니다.\\n\\n주요 책임:\\n- 대규모의 복잡한 데이터 세트를 수집, 분석, 해석하여 고객에게 실행 가능한 인사이트와 권장 사항을 제공합니다.\\n- 예측 모델, 시뮬레이션 및 데이터 기반 의사 결정 도구 개발\\n- 분석 결과를 효과적으로 전달하기 위해 데이터 시각화 및 대시보드 생성\\n- 고객과 긴밀히 협력하여 비즈니스 요구 사항을 이해하고 목표를 달성하기 위해 데이터 분석을 맞춤화합니다.\\n- 내부 팀과 협업하여 분석 방법론 및 프로세스를 개발하고 개선합니다.\\n- 데이터 분석 및 비즈니스 인텔리전스 도구의 업계 동향과 발전을 최신 상태로 유지합니다.\\n\\n자격 요건\\n- 수학, 통계학, 컴퓨터 과학 또는 공학과 같은 정량적 분야의 학사 학위 취득\\n- 데이터 분석 또는 비즈니스 인텔리전스 역할에서 최소 3~5년의 경력 보유\\n- 강력한 문제 해결 능력과 비판적이고 전략적으로 사고하는 능력\\n- R, Python, SQL, Tableau와 같은 데이터 분석 도구에 대한 숙련도\\n- 뛰어난 커뮤니케이션 및 프레젠테이션 기술\\n- 팀 환경 내에서 독립적으로 일할 수 있는 능력\\n- 강력한 프로젝트 관리 및 조직 기술\\n\\n데이터 분석 컨설턴트는 헌신적인 전문가 팀과 함께 도전적이고 흥미로운 프로젝트를 수행할 수 있는 기회를 갖게 됩니다. 경쟁력 있는 보상 패키지와 경력 성장 및 발전 기회를 제공합니다. 데이터와 분석에 대한 열정이 있고 새로운 도전을 찾고 있다면 여러분의 많은 지원을 바랍니다.',\n",
              " '잠시 매장을 방문해야 했습니다.',\n",
              " '부정적',\n",
              " \"주식 매매의 최대 이익을 찾는 한 가지 방법은 다음 알고리즘을 사용하는 것입니다:\\n\\n1. 지금까지 얻은 최대 이익을 나타내는 `maxProfit`과 지금까지 본 최저 가격을 나타내는 `minPrice`라는 두 변수를 초기화합니다. 최대 수익`을 0으로 설정하고 `최저 가격`을 첫 번째 주가로 설정합니다.\\n\\n2. 2. 둘째 날부터 각 날짜의 주가 배열을 반복합니다.\\n\\n3. 현재 날짜의 경우 현재 가격에서 '최소 가격'을 빼서 잠재 수익을 계산합니다.\\n\\n4. 잠재 수익이 현재 '최대 수익'보다 크면 '최대 수익' 값을 업데이트합니다.\\n\\n5. 현재 가격이 현재 `minPrice`보다 낮으면 `minPrice` 값을 업데이트합니다.\\n\\n6. 반복이 완료되면 `maxProfit` 값을 반환합니다.\\n\\n이 알고리즘은 지금까지 발생한 최대 수익을 추적하면서 최소 가격도 업데이트합니다. 매수가 매도보다 먼저 발생하도록 보장하며 항상 가능한 최대 이익을 반환합니다. 이 알고리즘의 시간 복잡도는 O(n)이며, 여기서 n은 주가를 사용할 수 있는 일수입니다.\",\n",
              " '그녀는 이벤트에 참여했습니다.',\n",
              " '고객님께,\\n\\n이 문제를 알려주셔서 감사합니다. 구매하신 제품에 만족하지 못하셨다니 유감입니다. 저희는 고객의 기대에 부응하는 고품질의 상품을 제공하기 위해 노력하고 있으며, 고객님께는 그렇지 못한 점에 대해 유감스럽게 생각합니다.\\n\\n구매하신 제품에 대한 환불 처리를 도와드리겠습니다. 주문을 찾아 환불 절차를 시작할 수 있도록 다음 세부 정보를 제공해 주시겠습니까?\\n\\n- 주문 번호\\n- 구매와 관련된 이름 및/또는 이메일 주소\\n- 구매 날짜\\n\\n이 정보를 확보하면 즉시 환불을 처리합니다.\\n\\n다시 한 번 불편을 끼쳐 드려 죄송하며, 이 문제를 해결하는 동안 기다려 주시고 이해해 주셔서 감사합니다.\\n\\n다시 한번 감사드립니다,\\n\\n[회사] 고객 지원',\n",
              " '1. 혁신이 성공하거나 영향력을 발휘하는 요인은 무엇인가요?\\n2. 혁신은 어떻게 경제 성장과 사회 발전을 촉진할까요?\\n3. 기업과 조직에서 혁신을 가로막는 장벽은 무엇인가요?\\n4. 기업 내에서 혁신을 어떻게 장려하고 지원할 수 있을까요?\\n5. 정부 정책과 규제는 혁신에 어떤 역할을 하나요?\\n6. 혁신은 산업을 어떻게 형성하며, 그 반대의 경우도 마찬가지인가요?\\n7. 지난 10년간의 주요 기술 혁신에는 어떤 것이 있나요?\\n8. 의학 및 의료 분야의 혁신을 통해 사회는 어떤 혜택을 얻나요?\\n9. 혁신의 잠재적인 윤리적, 사회적 영향은 무엇인가요?\\n10. 협업과 다양성은 혁신에 어떻게 기여하나요?',\n",
              " '가구를 구매할 때는 공간의 전체적인 미관을 고려하고 기존 가구 및 원하는 스타일과 어울리는지 확인하는 것이 중요합니다.',\n",
              " '\"매일 건강한 스낵으로 올바른 방법으로 에너지를 충전하세요!\"',\n",
              " '아멜리아 이어하트는 선구적인 비행가이자 대서양을 단독으로 횡단한 최초의 여성 비행사였습니다. 그녀는 수많은 기록을 경신하며 여성 파일럿 세대에 영감을 주었습니다. 1937년 세계 일주를 시도하던 중 실종된 사건은 역사상 가장 큰 미해결 미스터리 중 하나로 남아 있습니다.',\n",
              " '끔찍한 감기에 걸려서 괴롭습니다.',\n",
              " '내일 비가 오나요?',\n",
              " '그녀는 물품을 사러 매장에 왔습니다.',\n",
              " '강도들은 공범들을 배신했습니다.',\n",
              " '다른 정책과 마찬가지로 대학 무상 교육 제공에는 장단점이 있습니다.\\n\\n장점:\\n- 기회 균등: 무료 대학 교육을 제공하면 저소득층 및 소외 계층 학생들에게 재정적 장애물에 대한 걱정 없이 고등 교육을 받을 수 있는 동등한 기회를 제공함으로써 경쟁의 장을 평등하게 만들 수 있습니다.\\n- 경제 성장: 교육받은 노동력은 경제의 성장과 발전에 매우 중요합니다. 대학 교육이 무료로 제공되면 더 많은 사람들이 경제에 기여하는 데 필요한 기술과 지식을 습득할 수 있습니다.\\n- 부채 감소: 대학 교육은 매우 비싸기 때문에 학생들이 많은 빚을 지게 될 수 있습니다. 무료 대학 교육은 이러한 문제를 해결하여 학생들이 대학 부채에 대한 부담 없이 커리어를 시작할 수 있도록 합니다.\\n- 등록률 증가: 일부 학생들에게는 대학 교육 비용이 대학 진학을 방해하는 요인이 될 수 있습니다. 이러한 장벽을 제거하면 더 많은 학생들이 대학에 등록하고 고등 교육을 받도록 장려할 수 있습니다.\\n\\n\\n단점:\\n- 재정적 부담: 무료 대학 교육을 제공하려면 비용이 발생합니다. 이는 정부가 교육에 상당한 자금을 할당해야 한다는 것을 의미하며, 다른 중요한 프로그램이 삭감되거나 세금이 인상될 수 있습니다.\\n- 과밀화: 무상 대학 교육이 가져올 수 있는 등록자 증가로 인해 기존 대학이 과밀화되어 학급 규모가 커지고 학생을 위한 자원이 감소할 수 있습니다.\\n- 교육의 질 저하: 무상 교육 제공에 따른 재정적 부담으로 인해 장기적으로 교육의 질이 저하될 수 있으며, 특히 시설 유지, 우수한 교수진 유치 및 유지, 다양한 학문 분야의 최신 발전을 따라잡을 수 있는 자금이 충분하지 않은 경우 교육의 질이 저하될 수 있습니다.\\n- 가치 하락: 대학 졸업자 수가 증가함에 따라 동일한 일자리를 놓고 경쟁하는 졸업생들로 인해 취업 시장이 과포화 상태가 될 수 있으므로 대학 학위의 가치가 하락할 위험도 있습니다.',\n",
              " '윈드차임 소리는 부드럽고 온화하며 차분한 느낌을 주며, 멜로디가 울리거나 칙칙한 소리를 냅니다. 바람결에 춤을 추는 듯한 음색으로 기발하거나 미묘한 느낌으로 묘사되기도 합니다. 차임은 각 음이 순수하고 맑은 톤으로 울려 퍼져 조화롭고 차분한 분위기를 조성합니다. 금속 차임은 더 날카롭고 밝고 딸랑거리는 소리를 내는 반면, 대나무 차임은 부드럽게 바스락거리는 더 깊고 공명하는 소리를 냅니다. 전반적으로 풍금 소리는 평화롭고 편안하며 따뜻한 날의 산들바람을 연상시킵니다.',\n",
              " '환경 보호는 우리가 살고 있는 지구를 보호하고 미래 세대를 위해 천연자원과 생물 다양성을 보존하는 데 도움이 되므로 매우 중요합니다. 이는 기후 변화의 영향을 완화하는 것부터 전반적인 삶의 질을 개선하는 것까지 광범위한 이점을 가져올 수 있습니다.\\n\\n환경을 보호하지 못하면 생물 다양성이 손실되어 지구와 인류의 생존에 중대한 영향을 미칠 수 있습니다. 예를 들어, 특정 종의 손실은 먹이사슬이나 수분을 방해하여 생태계 전체에 문제가 발생하는 도미노 효과를 일으킬 수 있습니다. 또한 환경 보호가 제대로 이루어지지 않으면 공기, 물, 토양과 같은 천연 자원이 손상되어 인간의 건강과 복지에 큰 영향을 미칠 수 있습니다.\\n\\n환경 보호는 농업, 어업, 관광업 등 많은 산업의 근간을 이루는 천연자원의 지속 가능성을 보장하는 데 도움이 되므로 경제적 이익도 있습니다. 또한 경제에 막대한 영향을 미칠 수 있는 자연 재해를 예방하거나 완화하는 데에도 도움이 됩니다.\\n\\n요약하자면, 환경 보호는 지구를 보호하고, 자원과 생물 다양성을 보존하며, 건강과 경제적 이득을 모두 가져다주기 때문에 중요합니다. 환경을 보호함으로써 우리는 현재와 미래의 우리를 지원하고 지탱할 수 있습니다.',\n",
              " '그녀는 문을 열고 그림자에 가려진 키 큰 인물을 발견했습니다. 며칠 동안 집에 혼자 있었기 때문에 고립감의 무게가 느껴지기 시작한 그녀는 잠시 상상이 자신을 속이는 것이라고 생각했습니다. 하지만 어둠에 눈이 적응되자, 그녀는 그것이 상상의 속임수가 아니라 실제로 누군가 또는 무언가가 눈앞에 서 있는 것을 보았습니다.\\n\\n두려움에 떨며 그녀는 무슨 말을 해야 할지, 어떻게 행동해야 할지 몰라 뒤로 물러섰습니다. 그 형체는 어둠에 얼굴을 가린 채 움직이지 않고 서 있었습니다. 마침내 그 형체가 말을 걸었을 때 그녀는 도움을 요청하는 비명을 지르려고 했습니다.\\n\\n\"두려워하지 마세요.\" 그 형체가 깊고 부드러운 목소리로 말했다.\\n\\n그녀는 두려움보다 호기심이 앞선 채 걸음을 멈췄습니다. 그 형체가 앞으로 다가오자 안도감과 놀라움을 동시에 느낀 그녀는 그 형체가 몇 년 동안 보지 못했던 오랜 친구라는 것을 알았습니다.\\n\\n그를 보고 너무 기뻐서 그녀는 두 팔로 그를 끌어안고 행복의 눈물을 흘렸습니다. 그들은 밤새도록 이야기를 나누며 옛 추억을 회상했습니다. 그녀에게 찾아온 외로움을 떨쳐버리기 위해 꼭 필요한 시간이었습니다.\\n\\n새벽의 첫 빛이 창문을 통해 들어오기 시작하자 친구는 일어나 자리를 떠났습니다. 그녀는 친구의 떠남에 슬픔을 느끼며 그를 문 앞까지 데려다주었습니다. 하지만 그는 햇빛을 받으며 돌아서서 미소를 지었습니다.\\n\\n\"곧 돌아올 테니 걱정하지 마세요.\" 그가 말했습니다.\\n\\n그리고 그렇게 그는 아침 속으로 사라졌고, 그녀는 새로운 희망과 함께 때로는 가장 어두운 순간에도 예상치 못한 곳에서 도움이 올 수 있다는 사실을 알게 되었습니다.',\n",
              " '판매 보고서의 정확성이 부족했습니다.',\n",
              " '그린본드는 기후 변화의 영향을 완화하기 위해 재생 에너지 또는 에너지 효율과 같은 친환경 프로젝트에 자금을 조달하기 위해 자본 시장에서 발행되는 채무 상품입니다.',\n",
              " '\"우리 모두는 지구를 구하기 위해 각자의 역할이 있습니다. 환경 파괴에 맞서 싸우는 일은 쓰레기를 줄이고, 자원을 절약하고, 취약한 생태계를 보호하기 위한 작고 의식적인 결정에서 시작됩니다. 더 푸르고 밝은 미래를 만들기 위해 함께 노력합시다. 🌿 #지속가능성 #환경인식\"',\n",
              " \"문장에서 '자동차'와 '트럭' 사이의 관계 유형은 비교 유형 중 하나입니다.\",\n",
              " \"이 코드의 출력은 목록 'x'에 있는 각 요소의 제곱을 포함하는 새 목록 'y'입니다. 결과 목록 'y'는 [1, 4, 9, 16]입니다.\",\n",
              " '제공된 정보에 따르면 묘사된 동물은 고양이, 여우 또는 스라소니일 수 있습니다. 특정 동물을 정확하게 식별하려면 더 많은 정보가 필요합니다.',\n",
              " '\"호밀밭의 파수꾼\"은 J.D. 샐린저의 시대를 초월한 성장 소설로, 십대의 불안과 소외의 본질을 포착한 작품입니다. 1950년대를 배경으로, 사립학교에서 퇴학당하고 뉴욕의 거리를 방황하며 자신의 감정과 씨름하고 세상에서 자신의 자리를 찾기 위해 노력하는 문제아 십대 홀든 콜필드의 이야기를 다루고 있습니다. 샐린저의 생생한 문체와 홀든 캐릭터의 정직함이 이 책을 흥미진진하게 만들어 줍니다. 순수함과 성장의 복잡성이라는 주제가 날것 그대로의 사실적인 방식으로 묘사되어 있습니다. 어렸을 때 세상에서 길을 잃고 방황하는 것이 어떤 것인지 기억하는 사람이라면 꼭 읽어야 할 책입니다.',\n",
              " '그녀는 문제를 해결하고 있습니다.']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_dataset['output'][:200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cdec78e6",
      "metadata": {
        "id": "cdec78e6"
      },
      "outputs": [],
      "source": [
        "sampled_dataset = raw_dataset.select(range(50000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f4f0bc79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4f0bc79",
        "outputId": "0616191e-4e47-4886-cc2b-8821f6f7c489"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'instruction', 'input', 'output'],\n",
              "    num_rows: 50000\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36c40ebb",
      "metadata": {
        "id": "36c40ebb"
      },
      "source": [
        "## tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "87d9e725",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402,
          "referenced_widgets": [
            "f53e1b656c1a4ac591305fc192f9b960",
            "9a6b6dde16ff4df8bb1de4285d24a565",
            "065d4aad98464993a605ef7c48f8d71a",
            "c49fca3669444679b60fd9d5b3970cbd",
            "28b8c492464f4ac3a3c0cf1a14622f8b",
            "0721f7bed38846939c803842421924c4",
            "bd0b5856881945059ffe858bd0cd1ccf",
            "2fce5a7867c44d018dfb6504c2c902cf",
            "90d89aafd8da44e392da724faba2015a",
            "6e6098eff4ad496aa0e977077daae4cd",
            "2b2873fb8f304992b5ac677a870c4987",
            "9d44c7a8cea448e1bcd46af15e9207f9",
            "57cc862a3cfd4f80b9a5a2f4e7b3c65c",
            "30116764fb9843c9a5736b96a9d7ed2a",
            "2829a98fa339433fb3db596123ba8cd2",
            "49a032d7d6434a31b8da55276e44253c",
            "b5b4ba27487243da92d61802fa6cdd15",
            "f8800323849f42a5bc343acfdb2309a8",
            "6a3b4fb802b74890ac667c7c97e97cae",
            "ca55bb23d1404d5a90e29645f558f28b",
            "31421c93fd2c4c5fa86218b936a47836",
            "6c31965c3fcd44f584889386c859d5c0",
            "62a7538b0aa245eca945f1cf09d4bc37",
            "b2715560735247f29ebe1251448eff6c",
            "6814756f324540568290e6d73d464387",
            "0e0f032bc5f54bdfa6008bc5730c8379",
            "7dd7db3af54240158a2110daa180480a",
            "7099548cac3e418181f4747647f12a2d",
            "a6873eb70baf47a8946d7e311af7c17f",
            "84c23d43e0df444591810c6e2cd9c087",
            "fe903be241b44fee8358398e13afb6cf",
            "273e0da220d54c0bab79ab4d64b11506",
            "aa8ca48e926a49cd8b66e3bfa0ed1684",
            "c2d89f4dd67d40d0be9ae45b52b5c5e7",
            "d73e67a0ffa94651855d56fa474cedfa",
            "d240599164954aacbbe88f1b396e5ec0",
            "c209931df4544e278b8b1760ca36c78c",
            "0e540c0b53a0448e99abcfadad5e7273",
            "35005f07e8ab40fa99dbfaed89610642",
            "fcab689e4d344344be2832a3d7986191",
            "c863127a578d45c9b5302be502389280",
            "2da741097ed14148975f517968be636c",
            "8aafe9af18314d4093fbcf8bc528a39c",
            "03964712deb64dc191ba350e126bce30"
          ]
        },
        "id": "87d9e725",
        "outputId": "d4132dcf-9584-4fa8-e571-eb7889a69d3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mkh08\\OneDrive\\문서\\GitHub\\Ollama_TestCode\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LlamaTokenizerFast(name_or_path='psymon/KoLlama2-7b', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('psymon/KoLlama2-7b')\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6b378eb3",
      "metadata": {
        "id": "6b378eb3"
      },
      "outputs": [],
      "source": [
        "def get_training_corpus(ds):\n",
        "    return(\n",
        "        ds[i:i+1000]['output'] for i in range(0, len(ds), 1000)\n",
        "    )\n",
        "training_corpus = get_training_corpus(raw_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "013ec5f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "013ec5f1",
        "outputId": "1a98beb4-3bd8-42f8-e61c-ef58cfbae48f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['▁', '안', '<0xEB>', '<0x85>', '<0x95>', '하', '세', '요']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_text = \"안녕하세요\"\n",
        "\n",
        "tokenizer.tokenize(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c57835d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c57835d0",
        "outputId": "e35e3015-9045-46ac-855e-d1ca39555a89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [1, 29871, 31734, 238, 136, 152, 30944, 31578, 31527], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'length': [9]}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(sample_text, return_length=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2b9e8168",
      "metadata": {
        "id": "2b9e8168"
      },
      "outputs": [],
      "source": [
        "context_length = 128\n",
        "\n",
        "def tokenize(batch):\n",
        "    outputs = tokenizer(\n",
        "        batch['output'],\n",
        "        max_length=context_length,\n",
        "        truncation=True,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_length=True\n",
        "    )\n",
        "\n",
        "    input_batch = []\n",
        "    for length, input_ids in zip(outputs['length'], outputs['input_ids']):\n",
        "        if length==context_length:\n",
        "            input_batch.append(input_ids)\n",
        "    return {\"input_ids\": input_batch}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c9864fa3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "02904d6ac4e443a2b4aaa190c8fef202",
            "1d12623417424a20a1f0fc4bef8890a4",
            "4399a0c675ff4c67852aa8e7e4e8a55c",
            "9eee9677f5494298ba3dd3e420e5801a",
            "900b49db28574161822a686aa2ea9cf0",
            "e967a63567604e748d84a7e2b79faef4",
            "9009bbae9fc04768ac59c689c920087e",
            "d6c8d23df367482baa82613a35b31202",
            "8088a6ef1e994e20a886da3a1ef82027",
            "15f6908dfa0c4f0da881f4274d247597",
            "a625a5d5e34a408c854b79e35c64522f"
          ]
        },
        "id": "c9864fa3",
        "outputId": "c98272d1-0c1c-4c58-917f-9964ab0c196e"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = sampled_dataset.map(tokenize, batched=True, remove_columns=raw_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "596122d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "596122d8",
        "outputId": "a4e1dade-6a46-4b67-b3a9-506536b90a3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'alpaca_{idx}',\n",
              " 'instruction': '3원색이란 무엇인가요?',\n",
              " 'input': '',\n",
              " 'output': '세 가지 기본 색은 빨강, 파랑, 노랑입니다. 이 색은 다른 색을 혼합하여 만들 수 없고 다른 모든 색은 다양한 비율로 조합하여 만들 수 있기 때문에 원색이라고 부릅니다. 빛에 사용되는 첨가제 색상 시스템에서 원색은 빨강, 녹색, 파랑(RGB)입니다.'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdd38c8f",
      "metadata": {
        "id": "bdd38c8f"
      },
      "source": [
        "## load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ecc2b5ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecc2b5ea",
        "outputId": "83e55159-6ca8-48e2-924a-c2f840e52ad6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaConfig {\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 1,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 4096,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 11008,\n",
              "  \"max_position_embeddings\": 2048,\n",
              "  \"model_type\": \"llama\",\n",
              "  \"num_attention_heads\": 32,\n",
              "  \"num_hidden_layers\": 32,\n",
              "  \"num_key_value_heads\": 32,\n",
              "  \"pretraining_tp\": 1,\n",
              "  \"rms_norm_eps\": 1e-06,\n",
              "  \"rope_scaling\": null,\n",
              "  \"rope_theta\": 10000.0,\n",
              "  \"tie_word_embeddings\": false,\n",
              "  \"transformers_version\": \"4.38.0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 32000\n",
              "}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import LlamaConfig\n",
        "configuration = LlamaConfig()\n",
        "configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b388dce2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b388dce2",
        "outputId": "e528a9bc-1648-4c56-ea9e-1f96cf72f865"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 2, 32000)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9648d6f2",
      "metadata": {
        "id": "9648d6f2"
      },
      "outputs": [],
      "source": [
        "configuration = LlamaConfig(**{\n",
        "  \"bos_token_id\": 1,\n",
        "  \"eos_token_id\": 2,\n",
        "  \"hidden_act\": \"silu\",\n",
        "  \"hidden_size\": 512,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"intermediate_size\": 1376,\n",
        "  \"max_position_embeddings\": 128,\n",
        "  \"model_type\": \"llama\",\n",
        "  \"num_attention_heads\": 4,\n",
        "  \"num_hidden_layers\": 4,\n",
        "  \"pad_token_id\": 0,\n",
        "  \"rms_norm_eps\": 1e-06,\n",
        "  \"tie_word_embeddings\": False,\n",
        "  \"transformers_version\": \"4.28.0\",\n",
        "  \"use_cache\": True,\n",
        "  \"vocab_size\": 50257\n",
        "})\n",
        "#0.25B\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8680f44c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8680f44c",
        "outputId": "36861e32-678d-44c7-a0f3-cda898c65b9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(50257, 512, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-3): 4 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaSdpaAttention(\n",
              "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
              "          (up_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
              "          (down_proj): Linear(in_features=1376, out_features=512, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm()\n",
              "        (post_attention_layernorm): LlamaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import LlamaForCausalLM\n",
        "\n",
        "model = LlamaForCausalLM(configuration)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "418242ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "418242ab",
        "outputId": "4b952c74-6306-4ff0-dbd6-b44e69498912"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bb62f7ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb62f7ab",
        "outputId": "bf0cabcc-554f-46f8-a18e-9e92198257b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)\n",
        "0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "94e0a7cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94e0a7cd",
        "outputId": "33ee6577-def1-4e69-b0c3-671354a9e4d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    1, 29871,   239,   152,   143, 31137, 30826,   239,   169,   155,\n",
              "         29871,   238,   185,   135,   239,   135,   160, 31354, 29871, 31137,\n",
              "           237,   179,   160, 31054,   237,   181,   143, 29871,   239,   163,\n",
              "           132,   239,   160,   148, 30944, 31137, 29871,   239,   161,   139,\n",
              "           239,   141,   184, 31063, 30709, 29889, 29871, 30393,   238,   162]],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"알고리즘 분석은 고객에게\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "inputs.to(device)\n",
        "\n",
        "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
        "generate_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d55bd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "77d55bd2",
        "outputId": "8546a312-a1f5-4d56-abd1-30be768b574d"
      },
      "outputs": [],
      "source": [
        "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "924b02b2",
      "metadata": {
        "id": "924b02b2"
      },
      "source": [
        "## train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5fed72a1",
      "metadata": {
        "id": "5fed72a1"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "05695613",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05695613",
        "outputId": "2aee8067-0d16-4f86-a341-11a7f5a148db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids: torch.Size([3, 128])\n",
            "attention_mask: torch.Size([3, 128])\n",
            "labels: torch.Size([3, 128])\n"
          ]
        }
      ],
      "source": [
        "out = data_collator([tokenized_datasets[i] for i in range(3)])\n",
        "\n",
        "for key in out:\n",
        "    print(f\"{key}: {out[key].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d2f272d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2f272d5",
        "outputId": "5852fca8-46b9-49a9-ee37-0c49afc5b687"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([    1, 29871, 31578, 29871, 30903, 30811, 29871, 30827,   238,   182,\n",
              "           187, 29871,   239,   134,   140, 31354, 29871,   238,   188,   171]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " tensor([    1, 29871, 31578, 29871, 30903, 30811, 29871, 30827,   238,   182,\n",
              "           187, 29871,   239,   134,   140, 31354, 29871,   238,   188,   171]))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out['input_ids'][0][:20], out['attention_mask'][0][:20], out['labels'][0][:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "92c33124",
      "metadata": {
        "id": "92c33124"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 32\n",
        "logging_steps = 100\n",
        "learning_rate=3e-3\n",
        "# learning_rate=5e-4\n",
        "num_epochs=1\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir='testllama',\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    logging_steps=logging_steps,\n",
        "    save_steps=logging_steps,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.1,\n",
        "    warmup_steps=logging_steps,\n",
        "    lr_scheduler_type='cosine',\n",
        "    learning_rate=learning_rate,\n",
        "    fp16=True,\n",
        "    push_to_hub=False\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "397824ea",
      "metadata": {
        "id": "397824ea"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_datasets,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "fdcf2e0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "fdcf2e0a",
        "outputId": "fefa83a9-f4a7-4c49-d2c1-310dac0d8b2d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bd0e736baf24f52b277dfbf79c298e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/660 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 4.0778, 'grad_norm': 0.5614767074584961, 'learning_rate': 0.003, 'epoch': 0.15}\n",
            "{'loss': 1.9856, 'grad_norm': 0.26063272356987, 'learning_rate': 0.0027700862988424262, 'epoch': 0.3}\n",
            "{'loss': 1.6865, 'grad_norm': 0.23928052186965942, 'learning_rate': 0.002150825608676337, 'epoch': 0.45}\n",
            "{'loss': 1.5701, 'grad_norm': 0.21277426183223724, 'learning_rate': 0.0013320532858450383, 'epoch': 0.61}\n",
            "{'loss': 1.4812, 'grad_norm': 0.1996116191148758, 'learning_rate': 0.0005647652972118998, 'epoch': 0.76}\n",
            "{'loss': 1.4221, 'grad_norm': 0.18188048899173737, 'learning_rate': 8.417500453744864e-05, 'epoch': 0.91}\n",
            "{'train_runtime': 347.5709, 'train_samples_per_second': 486.355, 'train_steps_per_second': 1.899, 'train_loss': 1.9794911124489525, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=660, training_loss=1.9794911124489525, metrics={'train_runtime': 347.5709, 'train_samples_per_second': 486.355, 'train_steps_per_second': 1.899, 'train_loss': 1.9794911124489525, 'epoch': 1.0})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "qNqA6cMLXgDo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qNqA6cMLXgDo",
        "outputId": "44f66044-4128-41ec-88fb-5747c2137aea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'알고리즘 분석은 고객에게 적응하고 있습니다. 이러한 작업을 수행하고 있으며, 이는 새로운 생활 습관을 추적하고 있습니다. 이러'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"\"\"알고리즘 분석은 고객에게\"\"\"\n",
        "\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "inputs.to(device)\n",
        "\n",
        "generate_ids = model.generate(inputs.input_ids, max_length=128)\n",
        "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "iFNgpmxh4v5H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFNgpmxh4v5H",
        "outputId": "37fb965f-eae0-48d0-e99f-08319b05fe2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('pre_llama\\\\tokenizer_config.json',\n",
              " 'pre_llama\\\\special_tokens_map.json',\n",
              " 'pre_llama\\\\tokenizer.json')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained('pre_llama')\n",
        "tokenizer.save_pretrained('pre_llama')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T9DKKEf-ycoB",
      "metadata": {
        "id": "T9DKKEf-ycoB"
      },
      "source": [
        "# Instruction Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "vt6mgDYe4b3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt6mgDYe4b3b",
        "outputId": "d5f93e6c-f1dd-470b-89f9-cabafe1a975a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(50257, 512, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-3): 4 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaSdpaAttention(\n",
              "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
              "          (up_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
              "          (down_proj): Linear(in_features=1376, out_features=512, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm()\n",
              "        (post_attention_layernorm): LlamaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import LlamaForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"pre_llama\")\n",
        "model = LlamaForCausalLM.from_pretrained('pre_llama')\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "CEWYLN3zyfz1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEWYLN3zyfz1",
        "outputId": "93a32f70-af58-4da3-e32c-d86ad1dddf0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'alpaca_{idx}',\n",
              " 'instruction': '주어진 숫자를 오름차순으로 정렬합니다.',\n",
              " 'input': '2, 4, 0, 8, 3',\n",
              " 'output': '0, 2, 3, 4, 8.'}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_dataset[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "MAmhs0uAy4tc",
      "metadata": {
        "id": "MAmhs0uAy4tc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17685ac47f3b439e92a57403d1109373",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# def gen_prompt(element):\n",
        "#     prompt_format = \"\"\"#Instruction: %s \\n %s \\n #result: \\n %s\"\"\"\n",
        "#     return DatasetDict({'input': prompt_format%(element['instruction'], element['input'],  element['output'])})\n",
        "\n",
        "def gen_prompt(element):\n",
        "    instruction = element['instruction']\n",
        "    input_text = element['input']\n",
        "    output_text = element['output']\n",
        "\n",
        "    # 줄바꿈 문자를 포함하여 문자열 포맷팅\n",
        "    prompt_format = f\"지시: {instruction} \\n {input_text}\\n 결과: {output_text}\"\n",
        "\n",
        "    return DatasetDict({'input': prompt_format})\n",
        "\n",
        "\n",
        "dataset = sampled_dataset.map(gen_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "FEQcx8V92ENY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEQcx8V92ENY",
        "outputId": "83507b3f-2bf7-4dd9-dfb2-528bd8bc404e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'alpaca_{idx}',\n",
              " 'instruction': '주어진 숫자를 오름차순으로 정렬합니다.',\n",
              " 'input': '지시: 주어진 숫자를 오름차순으로 정렬합니다. \\n 2, 4, 0, 8, 3\\n 결과: 0, 2, 3, 4, 8.',\n",
              " 'output': '0, 2, 3, 4, 8.'}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "kZao41bLzJGU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "a6ff4bba196c43099df979a119c9b895",
            "db4691c4f9ac43a8a6803a990e35508d",
            "1f655fd735fd4e68a0713b6c174e3c23",
            "5b7df83922314dc0b9870256e4d4c811",
            "b1ee8eb8f4334aecbc23b9483b2461c9",
            "7e19e893897542bc877417cb013776d2",
            "8ddbd57160374d0d90a0485bafaaec2b",
            "915bc5d3ab7b498c854fa488819117b1",
            "d2f01b4de4a540b08f0a81d299fc8306",
            "b02958698bbc41129981ae4944811a99",
            "20893d655fdd4d6f86f9103fe97953d0"
          ]
        },
        "id": "kZao41bLzJGU",
        "outputId": "2175f0c3-b1e9-4fd3-9c3e-18139d21120e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97b4ec5bd6824cf5a811574929570aad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids'],\n",
              "    num_rows: 50000\n",
              "})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def tokenize(element):\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    outputs = tokenizer(\n",
        "        element['input'],\n",
        "        truncation=True,\n",
        "        max_length=context_length,\n",
        "        return_overflowing_tokens=False,\n",
        "        return_length=True,\n",
        "        padding=True\n",
        "    )\n",
        "    input_batch = []\n",
        "    for input, input_ids, output in zip(element[\"input\"], outputs[\"input_ids\"], element['output']):\n",
        "        input_batch.append(input_ids)\n",
        "    return {\"input_ids\": input_batch}\n",
        "\n",
        "context_length=128\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize, batched=True, remove_columns=raw_dataset.column_names\n",
        ")\n",
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "2MQpABGE3b0m",
      "metadata": {
        "id": "2MQpABGE3b0m"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "-JofV66V3c6y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JofV66V3c6y",
        "outputId": "e3990409-5455-4af1-ffa5-8104e8cf6aae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids shape: torch.Size([5, 128])\n",
            "attention_mask shape: torch.Size([5, 128])\n",
            "labels shape: torch.Size([5, 128])\n"
          ]
        }
      ],
      "source": [
        "out = data_collator([tokenized_datasets[i] for i in range(5)])\n",
        "for key in out:\n",
        "    print(f\"{key} shape: {out[key].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "X-VWJCnd3drO",
      "metadata": {
        "id": "X-VWJCnd3drO"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"test_llama_inst\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    logging_steps=1000,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.1,\n",
        "    warmup_steps=1000,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    learning_rate=5e-4,\n",
        "    save_steps=1000,\n",
        "    fp16=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_datasets,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "XDyHwTCe30Cj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "XDyHwTCe30Cj",
        "outputId": "e326f4d7-9ce7-466e-8d0a-7ebebadacb3c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "972e05c888404fa3a3905dccab8c5e6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1562 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.2987, 'grad_norm': 0.5819985270500183, 'learning_rate': 0.0005, 'epoch': 0.64}\n",
            "{'train_runtime': 201.6207, 'train_samples_per_second': 247.99, 'train_steps_per_second': 7.747, 'train_loss': 1.265442324356294, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1562, training_loss=1.265442324356294, metrics={'train_runtime': 201.6207, 'train_samples_per_second': 247.99, 'train_steps_per_second': 7.747, 'train_loss': 1.265442324356294, 'epoch': 1.0})"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "I5MCr8Pz31eP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I5MCr8Pz31eP",
        "outputId": "28e175b8-177e-4003-ded7-a2f2257da3e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'#지시:주어진 숫자를 오름차순으로 정렬합니다. \\n 2, 4, 0, 8, 3\\n \\n#결과: 숫자 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"주어진 숫자를 오름차순으로 정렬합니다. \\n 2, 4, 0, 8, 3\\n \"\n",
        "prompt = f\"\"\"#지시:{question}\n",
        "#결과: \"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "inputs.to(device)\n",
        "\n",
        "generate_ids = model.generate(inputs.input_ids, max_length=128)\n",
        "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "fqMlqve-AyLp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "fqMlqve-AyLp",
        "outputId": "49d85976-90e6-4b3e-d34f-bedc2caaa8f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'#지시:머신러닝을 사용하여 일상적인 작업을 자동화하는 방법을 설명합니다.\\n#결과: 머신 러닝 알고리즘은 머신 러닝 알고리즘을 사용하여 생산성을 높이는 �'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"머신러닝을 사용하여 일상적인 작업을 자동화하는 방법을 설명합니다.\"\n",
        "prompt = f\"\"\"#지시:{question}\n",
        "#결과: \"\"\"\n",
        "\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "inputs.to(device)\n",
        "\n",
        "generate_ids = model.generate(inputs.input_ids, max_length=128)\n",
        "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ZxVduuWgCt-L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxVduuWgCt-L",
        "outputId": "dba3741a-4b07-4a6c-b60d-ae1fb94636ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('inst_llama\\\\tokenizer_config.json',\n",
              " 'inst_llama\\\\special_tokens_map.json',\n",
              " 'inst_llama\\\\tokenizer.json')"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained('inst_llama')\n",
        "tokenizer.save_pretrained('inst_llama')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nu7oV85mLkDw",
      "metadata": {
        "id": "nu7oV85mLkDw"
      },
      "source": [
        "# PeFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "TqyqafsEMi9n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqyqafsEMi9n",
        "outputId": "124e2174-6675-44e5-f8ca-19e7a6aab966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: peft in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from peft) (23.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from peft) (5.9.8)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from peft) (2.3.1+cu118)\n",
            "Requirement already satisfied: transformers in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from peft) (4.38.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from peft) (4.66.4)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from peft) (0.27.1)\n",
            "Requirement already satisfied: safetensors in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from peft) (0.23.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2023.10.0)\n",
            "Requirement already satisfied: requests in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (1.12.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (2021.4.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from transformers->peft) (0.15.2)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft) (2021.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\mkh08\\onedrive\\문서\\github\\ollama_testcode\\venv\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "1_wFMr-lMtIK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_wFMr-lMtIK",
        "outputId": "1188005e-f339-40a9-e369-7996841bb3c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "Qen14DsrLipg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qen14DsrLipg",
        "outputId": "091831f2-c9d4-4a22-8c5b-930a09eb5f6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(50257, 512, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-3): 4 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaSdpaAttention(\n",
              "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
              "          (up_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
              "          (down_proj): Linear(in_features=1376, out_features=512, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm()\n",
              "        (post_attention_layernorm): LlamaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import LlamaForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('inst_llama')\n",
        "model = LlamaForCausalLM.from_pretrained('inst_llama')\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "8SNHsVnDLtbo",
      "metadata": {
        "id": "8SNHsVnDLtbo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<TaskType.SEQ_CLS: 'SEQ_CLS'>,\n",
              " <TaskType.SEQ_2_SEQ_LM: 'SEQ_2_SEQ_LM'>,\n",
              " <TaskType.CAUSAL_LM: 'CAUSAL_LM'>,\n",
              " <TaskType.TOKEN_CLS: 'TOKEN_CLS'>,\n",
              " <TaskType.QUESTION_ANS: 'QUESTION_ANS'>,\n",
              " <TaskType.FEATURE_EXTRACTION: 'FEATURE_EXTRACTION'>]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "list(TaskType)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "Ez5FeOp6LyI2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez5FeOp6LyI2",
        "outputId": "fe41b5cf-f8ec-4857-9ae1-f721536d3fd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(50257, 512, padding_idx=0)\n",
              "        (layers): ModuleList(\n",
              "          (0-3): 4 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaSdpaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=512, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=512, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
              "              (up_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
              "              (down_proj): Linear(in_features=1376, out_features=512, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm()\n",
              "            (post_attention_layernorm): LlamaRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=512, out_features=50257, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM,\n",
        "                        inference_mode=False,\n",
        "                        r=16,\n",
        "                        lora_alpha=16, \n",
        "                        lora_dropout=0.1)\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "2eHNB7l1MfOU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eHNB7l1MfOU",
        "outputId": "816fe4fa-8926-4185-d0b9-de20c017e811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 262,144 || all params: 64,378,368 || trainable%: 0.40719267689420147\n"
          ]
        }
      ],
      "source": [
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "sHv_ZyyOO1EB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHv_ZyyOO1EB",
        "outputId": "e7ca1902-8a2e-4bd6-83d3-4dab1ee92f0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids shape: torch.Size([5, 128])\n",
            "attention_mask shape: torch.Size([5, 128])\n",
            "labels shape: torch.Size([5, 128])\n"
          ]
        }
      ],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        "\n",
        "out = data_collator([tokenized_datasets[i] for i in range(5)])\n",
        "for key in out:\n",
        "    print(f\"{key} shape: {out[key].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "xmWrOVrHPLNn",
      "metadata": {
        "id": "xmWrOVrHPLNn"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"peft_llama\",\n",
        "    per_device_train_batch_size=4,\n",
        "    logging_steps=500,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.1,\n",
        "    warmup_steps=500,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    learning_rate=5e-4,\n",
        "    save_steps=1000,\n",
        "    fp16=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_datasets,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "2qZm8K6JPlaH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "2qZm8K6JPlaH",
        "outputId": "c135175d-26c1-499a-9426-01045c38e9b2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "554bb47957ae40f190c4e5ef806d7197",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1562 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.144, 'grad_norm': 0.026584060862660408, 'learning_rate': 0.0005, 'epoch': 0.32}\n",
            "{'loss': 1.1116, 'grad_norm': 0.0339759886264801, 'learning_rate': 0.00027289381569935167, 'epoch': 0.64}\n",
            "{'loss': 1.0791, 'grad_norm': 0.034287773072719574, 'learning_rate': 4.193014378207044e-06, 'epoch': 0.96}\n",
            "{'train_runtime': 191.5604, 'train_samples_per_second': 261.014, 'train_steps_per_second': 8.154, 'train_loss': 1.1130574430302071, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1562, training_loss=1.1130574430302071, metrics={'train_runtime': 191.5604, 'train_samples_per_second': 261.014, 'train_steps_per_second': 8.154, 'train_loss': 1.1130574430302071, 'epoch': 1.0})"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "QZbM5tyvP-a4",
      "metadata": {
        "id": "QZbM5tyvP-a4"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('peft_llama_adapter')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8bXaXwsQWpm",
      "metadata": {
        "id": "f8bXaXwsQWpm"
      },
      "source": [
        "# PEFT Model LOAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "SS3Q9ZnxQXWp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS3Q9ZnxQXWp",
        "outputId": "03d06cc6-f822-45a7-913e-1c22b48784e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(50257, 512, padding_idx=0)\n",
              "        (layers): ModuleList(\n",
              "          (0-3): 4 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaSdpaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=512, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=512, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
              "              (up_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
              "              (down_proj): Linear(in_features=1376, out_features=512, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm()\n",
              "            (post_attention_layernorm): LlamaRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=512, out_features=50257, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import LlamaForCausalLM\n",
        "from peft import PeftModel, PeftConfig\n",
        "base_model =  LlamaForCausalLM.from_pretrained('inst_llama')\n",
        "model_load = PeftModel.from_pretrained(base_model, 'peft_llama_adapter')\n",
        "model_load.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "6mgcLWDoV8bI",
      "metadata": {
        "id": "6mgcLWDoV8bI"
      },
      "outputs": [],
      "source": [
        "model = model_load.merge_and_unload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "2GGr0EgaRuzl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GGr0EgaRuzl",
        "outputId": "e946abd4-ed7e-45f8-c44d-51f5ea1ade0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0020065307617188"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.stat('peft_llama_adapter/adapter_model.safetensors').st_size/(1024*1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "PIgxVPgeTbEC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIgxVPgeTbEC",
        "outputId": "6baf65cb-5909-436a-aaf7-203d1d72abb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "244.58809661865234"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.stat(\"inst_llama/model.safetensors\").st_size/(1024*1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "OYMkFrkcRwys",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYMkFrkcRwys",
        "outputId": "17db1c6e-aa5c-42c7-952b-fe87eff91a22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    1,   396, 30811, 30889, 29901, 30981, 31129, 31536, 29871,   239,\n",
              "           139,   174, 31013, 31517, 29871, 31346,   238,   169,   135, 31817,\n",
              "           239,   139,   159,   239,   159,   191, 30906, 29871, 30852,   238,\n",
              "           163,   175, 31980, 31063, 30709, 29889, 29871,    13, 29871, 29906,\n",
              "         29892, 29871, 29946, 29892, 29871, 29900, 29892, 29871, 29947, 29892,\n",
              "         29871, 29941,    13, 29871,    13, 29937,   237,   181,   179, 31906,\n",
              "         29901, 29871]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"주어진 숫자를 오름차순으로 정렬합니다. \\n 2, 4, 0, 8, 3\\n \"\n",
        "prompt = f\"\"\"#지시:{question}\n",
        "#결과: \"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "inputs.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "Wbk7G7nuSull",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Wbk7G7nuSull",
        "outputId": "6e7301ee-81a9-4462-cffc-e5ca64d99cd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'#지시:주어진 숫자를 오름차순으로 정렬합니다. \\n 2, 4, 0, 8, 3\\n \\n#결과: 숫자 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10'"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_ids = model.generate(inputs.input_ids, max_length=128)\n",
        "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02904d6ac4e443a2b4aaa190c8fef202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d12623417424a20a1f0fc4bef8890a4",
              "IPY_MODEL_4399a0c675ff4c67852aa8e7e4e8a55c",
              "IPY_MODEL_9eee9677f5494298ba3dd3e420e5801a"
            ],
            "layout": "IPY_MODEL_900b49db28574161822a686aa2ea9cf0"
          }
        },
        "03964712deb64dc191ba350e126bce30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "065d4aad98464993a605ef7c48f8d71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fce5a7867c44d018dfb6504c2c902cf",
            "max": 749,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90d89aafd8da44e392da724faba2015a",
            "value": 749
          }
        },
        "0721f7bed38846939c803842421924c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e0f032bc5f54bdfa6008bc5730c8379": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_273e0da220d54c0bab79ab4d64b11506",
            "placeholder": "​",
            "style": "IPY_MODEL_aa8ca48e926a49cd8b66e3bfa0ed1684",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 1.89MB/s]"
          }
        },
        "0e540c0b53a0448e99abcfadad5e7273": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15f6908dfa0c4f0da881f4274d247597": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d12623417424a20a1f0fc4bef8890a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e967a63567604e748d84a7e2b79faef4",
            "placeholder": "​",
            "style": "IPY_MODEL_9009bbae9fc04768ac59c689c920087e",
            "value": "Map: 100%"
          }
        },
        "1f655fd735fd4e68a0713b6c174e3c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_915bc5d3ab7b498c854fa488819117b1",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2f01b4de4a540b08f0a81d299fc8306",
            "value": 50000
          }
        },
        "20893d655fdd4d6f86f9103fe97953d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "273e0da220d54c0bab79ab4d64b11506": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2829a98fa339433fb3db596123ba8cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31421c93fd2c4c5fa86218b936a47836",
            "placeholder": "​",
            "style": "IPY_MODEL_6c31965c3fcd44f584889386c859d5c0",
            "value": " 500k/500k [00:00&lt;00:00, 644kB/s]"
          }
        },
        "28b8c492464f4ac3a3c0cf1a14622f8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b2873fb8f304992b5ac677a870c4987": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2da741097ed14148975f517968be636c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fce5a7867c44d018dfb6504c2c902cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30116764fb9843c9a5736b96a9d7ed2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a3b4fb802b74890ac667c7c97e97cae",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca55bb23d1404d5a90e29645f558f28b",
            "value": 499723
          }
        },
        "31421c93fd2c4c5fa86218b936a47836": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35005f07e8ab40fa99dbfaed89610642": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4399a0c675ff4c67852aa8e7e4e8a55c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c8d23df367482baa82613a35b31202",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8088a6ef1e994e20a886da3a1ef82027",
            "value": 50000
          }
        },
        "49a032d7d6434a31b8da55276e44253c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57cc862a3cfd4f80b9a5a2f4e7b3c65c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5b4ba27487243da92d61802fa6cdd15",
            "placeholder": "​",
            "style": "IPY_MODEL_f8800323849f42a5bc343acfdb2309a8",
            "value": "tokenizer.model: 100%"
          }
        },
        "5b7df83922314dc0b9870256e4d4c811": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b02958698bbc41129981ae4944811a99",
            "placeholder": "​",
            "style": "IPY_MODEL_20893d655fdd4d6f86f9103fe97953d0",
            "value": " 50000/50000 [00:09&lt;00:00, 4937.47 examples/s]"
          }
        },
        "62a7538b0aa245eca945f1cf09d4bc37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2715560735247f29ebe1251448eff6c",
              "IPY_MODEL_6814756f324540568290e6d73d464387",
              "IPY_MODEL_0e0f032bc5f54bdfa6008bc5730c8379"
            ],
            "layout": "IPY_MODEL_7dd7db3af54240158a2110daa180480a"
          }
        },
        "6814756f324540568290e6d73d464387": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c23d43e0df444591810c6e2cd9c087",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe903be241b44fee8358398e13afb6cf",
            "value": 1842767
          }
        },
        "6a3b4fb802b74890ac667c7c97e97cae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c31965c3fcd44f584889386c859d5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e6098eff4ad496aa0e977077daae4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7099548cac3e418181f4747647f12a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd7db3af54240158a2110daa180480a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e19e893897542bc877417cb013776d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8088a6ef1e994e20a886da3a1ef82027": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84c23d43e0df444591810c6e2cd9c087": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aafe9af18314d4093fbcf8bc528a39c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ddbd57160374d0d90a0485bafaaec2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9009bbae9fc04768ac59c689c920087e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "900b49db28574161822a686aa2ea9cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90d89aafd8da44e392da724faba2015a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "915bc5d3ab7b498c854fa488819117b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a6b6dde16ff4df8bb1de4285d24a565": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0721f7bed38846939c803842421924c4",
            "placeholder": "​",
            "style": "IPY_MODEL_bd0b5856881945059ffe858bd0cd1ccf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9d44c7a8cea448e1bcd46af15e9207f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57cc862a3cfd4f80b9a5a2f4e7b3c65c",
              "IPY_MODEL_30116764fb9843c9a5736b96a9d7ed2a",
              "IPY_MODEL_2829a98fa339433fb3db596123ba8cd2"
            ],
            "layout": "IPY_MODEL_49a032d7d6434a31b8da55276e44253c"
          }
        },
        "9eee9677f5494298ba3dd3e420e5801a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f6908dfa0c4f0da881f4274d247597",
            "placeholder": "​",
            "style": "IPY_MODEL_a625a5d5e34a408c854b79e35c64522f",
            "value": " 50000/50000 [00:15&lt;00:00, 2830.30 examples/s]"
          }
        },
        "a625a5d5e34a408c854b79e35c64522f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6873eb70baf47a8946d7e311af7c17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6ff4bba196c43099df979a119c9b895": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db4691c4f9ac43a8a6803a990e35508d",
              "IPY_MODEL_1f655fd735fd4e68a0713b6c174e3c23",
              "IPY_MODEL_5b7df83922314dc0b9870256e4d4c811"
            ],
            "layout": "IPY_MODEL_b1ee8eb8f4334aecbc23b9483b2461c9"
          }
        },
        "aa8ca48e926a49cd8b66e3bfa0ed1684": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b02958698bbc41129981ae4944811a99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1ee8eb8f4334aecbc23b9483b2461c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2715560735247f29ebe1251448eff6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7099548cac3e418181f4747647f12a2d",
            "placeholder": "​",
            "style": "IPY_MODEL_a6873eb70baf47a8946d7e311af7c17f",
            "value": "tokenizer.json: 100%"
          }
        },
        "b5b4ba27487243da92d61802fa6cdd15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0b5856881945059ffe858bd0cd1ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c209931df4544e278b8b1760ca36c78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aafe9af18314d4093fbcf8bc528a39c",
            "placeholder": "​",
            "style": "IPY_MODEL_03964712deb64dc191ba350e126bce30",
            "value": " 414/414 [00:00&lt;00:00, 32.7kB/s]"
          }
        },
        "c2d89f4dd67d40d0be9ae45b52b5c5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d73e67a0ffa94651855d56fa474cedfa",
              "IPY_MODEL_d240599164954aacbbe88f1b396e5ec0",
              "IPY_MODEL_c209931df4544e278b8b1760ca36c78c"
            ],
            "layout": "IPY_MODEL_0e540c0b53a0448e99abcfadad5e7273"
          }
        },
        "c49fca3669444679b60fd9d5b3970cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e6098eff4ad496aa0e977077daae4cd",
            "placeholder": "​",
            "style": "IPY_MODEL_2b2873fb8f304992b5ac677a870c4987",
            "value": " 749/749 [00:00&lt;00:00, 41.5kB/s]"
          }
        },
        "c863127a578d45c9b5302be502389280": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca55bb23d1404d5a90e29645f558f28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d240599164954aacbbe88f1b396e5ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c863127a578d45c9b5302be502389280",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2da741097ed14148975f517968be636c",
            "value": 414
          }
        },
        "d2f01b4de4a540b08f0a81d299fc8306": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6c8d23df367482baa82613a35b31202": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d73e67a0ffa94651855d56fa474cedfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35005f07e8ab40fa99dbfaed89610642",
            "placeholder": "​",
            "style": "IPY_MODEL_fcab689e4d344344be2832a3d7986191",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "db4691c4f9ac43a8a6803a990e35508d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e19e893897542bc877417cb013776d2",
            "placeholder": "​",
            "style": "IPY_MODEL_8ddbd57160374d0d90a0485bafaaec2b",
            "value": "Map: 100%"
          }
        },
        "e967a63567604e748d84a7e2b79faef4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f53e1b656c1a4ac591305fc192f9b960": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a6b6dde16ff4df8bb1de4285d24a565",
              "IPY_MODEL_065d4aad98464993a605ef7c48f8d71a",
              "IPY_MODEL_c49fca3669444679b60fd9d5b3970cbd"
            ],
            "layout": "IPY_MODEL_28b8c492464f4ac3a3c0cf1a14622f8b"
          }
        },
        "f8800323849f42a5bc343acfdb2309a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcab689e4d344344be2832a3d7986191": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe903be241b44fee8358398e13afb6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
